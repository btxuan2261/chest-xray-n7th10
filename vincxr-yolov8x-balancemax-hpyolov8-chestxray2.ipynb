{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f255e21",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-09-24T10:50:26.989797Z",
     "iopub.status.busy": "2024-09-24T10:50:26.989286Z",
     "iopub.status.idle": "2024-09-24T10:51:46.974968Z",
     "shell.execute_reply": "2024-09-24T10:51:46.973959Z"
    },
    "papermill": {
     "duration": 80.004368,
     "end_time": "2024-09-24T10:51:46.977318",
     "exception": false,
     "start_time": "2024-09-24T10:50:26.972950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q ultralytics\n",
    "!pip install -q albumentations\n",
    "!pip install -q torch torchvision\n",
    "!pip install -q pyyaml\n",
    "!pip install -q wandb\n",
    "!pip install -q torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcb009ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:46.997799Z",
     "iopub.status.busy": "2024-09-24T10:51:46.997473Z",
     "iopub.status.idle": "2024-09-24T10:51:56.461947Z",
     "shell.execute_reply": "2024-09-24T10:51:56.460925Z"
    },
    "papermill": {
     "duration": 9.477262,
     "end_time": "2024-09-24T10:51:56.464473",
     "exception": false,
     "start_time": "2024-09-24T10:51:46.987211",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "import yaml\n",
    "from albumentations import Compose, RandomRotate90, Flip, Transpose, ShiftScaleRotate, RandomBrightnessContrast\n",
    "from ultralytics import YOLO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb5d1fe6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:56.486093Z",
     "iopub.status.busy": "2024-09-24T10:51:56.485302Z",
     "iopub.status.idle": "2024-09-24T10:51:57.611862Z",
     "shell.execute_reply": "2024-09-24T10:51:57.610875Z"
    },
    "papermill": {
     "duration": 1.138847,
     "end_time": "2024-09-24T10:51:57.613856",
     "exception": false,
     "start_time": "2024-09-24T10:51:56.475009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wandb login successful.\n"
     ]
    }
   ],
   "source": [
    "# Setup wandb securely\n",
    "# It's recommended to set the WANDB_API_KEY as an environment variable for security\n",
    "# For example, in your environment, set WANDB_API_KEY=your_key\n",
    "# Here, we retrieve it using os.getenv. If not set, you can manually input or handle accordingly.\n",
    "wandb_api_key = '4f88ff0bbc6e3485258bca7079d7da4c47798ccd' #os.getenv('WANDB_API_KEY')\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "    print(\"Wandb login successful.\")\n",
    "else:\n",
    "    # Handle the absence of the API key appropriately\n",
    "    # For security, avoid hardcoding the key. Instead, prompt the user or skip logging in.\n",
    "    print(\"Wandb API key not found. Skipping wandb login.\")\n",
    "\n",
    "# # Initialize a new wandb run (only if logged in)\n",
    "# if wandb_api_key:\n",
    "#     wandb.init(project='vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray', name='time11hour', reinit=True)\n",
    "\n",
    "# Define paths to data directories\n",
    "ROOT = Path(\"/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2896aaa8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:57.635442Z",
     "iopub.status.busy": "2024-09-24T10:51:57.635146Z",
     "iopub.status.idle": "2024-09-24T10:51:57.639719Z",
     "shell.execute_reply": "2024-09-24T10:51:57.638867Z"
    },
    "papermill": {
     "duration": 0.017674,
     "end_time": "2024-09-24T10:51:57.641752",
     "exception": false,
     "start_time": "2024-09-24T10:51:57.624078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def ls(path: Path) -> List[Path]:\n",
    "    \"\"\"List all files and directories in the given path.\"\"\"\n",
    "    return list(path.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f30db35c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:57.662413Z",
     "iopub.status.busy": "2024-09-24T10:51:57.662132Z",
     "iopub.status.idle": "2024-09-24T10:51:57.676902Z",
     "shell.execute_reply": "2024-09-24T10:51:57.675922Z"
    },
    "papermill": {
     "duration": 0.027335,
     "end_time": "2024-09-24T10:51:57.678864",
     "exception": false,
     "start_time": "2024-09-24T10:51:57.651529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of ROOT directory:\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/val.txt\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/test.txt\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/data.yaml\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train.txt\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/val\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/test\n",
      "/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train\n"
     ]
    }
   ],
   "source": [
    "# List contents of ROOT to verify data structure\n",
    "print(\"Contents of ROOT directory:\")\n",
    "for item in ls(ROOT):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "689214e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:57.700793Z",
     "iopub.status.busy": "2024-09-24T10:51:57.700473Z",
     "iopub.status.idle": "2024-09-24T10:51:58.019948Z",
     "shell.execute_reply": "2024-09-24T10:51:58.018914Z"
    },
    "papermill": {
     "duration": 0.332751,
     "end_time": "2024-09-24T10:51:58.022047",
     "exception": false,
     "start_time": "2024-09-24T10:51:57.689296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Number of images per class\n",
    "class_counts = [5481, 255, 851, 4046, 519, 904, 1097, 2188, 2324, 1945, 2190, 4308, 195, 4097, 15525, 29347]\n",
    "\n",
    "# Compute class-balanced weights\n",
    "beta = 0.9999\n",
    "effective_num = 1.0 - np.power(beta, class_counts)\n",
    "weights = (1.0 - beta) / effective_num\n",
    "weights = weights / np.sum(weights) * len(class_counts)\n",
    "\n",
    "# Assign to device dynamically\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "weights = torch.tensor(weights).float().to(device)\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Define Class-balanced Focal Loss\n",
    "class CBFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    Class-Balanced Focal Loss to address class imbalance.\n",
    "    \"\"\"\n",
    "    def __init__(self, weights, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "        self.gamma = gamma\n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        \"\"\"\n",
    "        Compute the focal loss between `logits` and the ground truth `labels`.\n",
    "\n",
    "        Args:\n",
    "            logits (Tensor): Predicted logits with shape (N, C).\n",
    "            labels (Tensor): Ground truth class indices with shape (N,).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar loss value.\n",
    "        \"\"\"\n",
    "        ce_loss = F.cross_entropy(logits, labels, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        focal_loss = (self.weights[labels] * (1 - pt)**self.gamma * ce_loss).mean()\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "031c1ba5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.043228Z",
     "iopub.status.busy": "2024-09-24T10:51:58.042902Z",
     "iopub.status.idle": "2024-09-24T10:51:58.046998Z",
     "shell.execute_reply": "2024-09-24T10:51:58.046235Z"
    },
    "papermill": {
     "duration": 0.01675,
     "end_time": "2024-09-24T10:51:58.048845",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.032095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the updated loss function\n",
    "focal_loss = CBFocalLoss(weights).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dac309c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.070485Z",
     "iopub.status.busy": "2024-09-24T10:51:58.070162Z",
     "iopub.status.idle": "2024-09-24T10:51:58.083651Z",
     "shell.execute_reply": "2024-09-24T10:51:58.082847Z"
    },
    "papermill": {
     "duration": 0.026904,
     "end_time": "2024-09-24T10:51:58.085553",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.058649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use callbacks to monkey-patch the YOLODataset class with a weighted dataset\n",
    "def patch_dataset(trainer):\n",
    "    \"\"\"\n",
    "    Monkey-patch the YOLODataset to implement a weighted dataset for class balancing.\n",
    "\n",
    "    Args:\n",
    "        trainer: The YOLO trainer instance.\n",
    "    \"\"\"\n",
    "    from ultralytics.data.dataset import YOLODataset\n",
    "    import ultralytics.data.build as build\n",
    "    import numpy as np\n",
    "\n",
    "    class YOLOWeightedDataset(YOLODataset):\n",
    "        \"\"\"\n",
    "        A weighted dataset that samples images based on class frequencies.\n",
    "        \"\"\"\n",
    "        def __init__(self, *args, mode=\"train\", **kwargs):\n",
    "            super(YOLOWeightedDataset, self).__init__(*args, **kwargs)\n",
    "            self.train_mode = \"train\" in self.prefix\n",
    "            self.count_instances()\n",
    "            class_weights = np.sum(self.counts) / self.counts\n",
    "            self.class_weights = np.array(class_weights)\n",
    "            self.weights = self.calculate_weights()\n",
    "            self.probabilities = self.calculate_probabilities()\n",
    "\n",
    "        def count_instances(self):\n",
    "            \"\"\"Count the number of instances per class.\"\"\"\n",
    "            self.counts = [0 for _ in range(len(self.data[\"names\"]))]\n",
    "            for label in self.labels:\n",
    "                cls = label['cls'].reshape(-1).astype(int)\n",
    "                for id in cls:\n",
    "                    self.counts[id] += 1\n",
    "            self.counts = np.array(self.counts)\n",
    "            self.counts = np.where(self.counts == 0, 1, self.counts)\n",
    "\n",
    "        def calculate_weights(self):\n",
    "            \"\"\"Calculate weights for each label based on class weights.\"\"\"\n",
    "            weights = []\n",
    "            for label in self.labels:\n",
    "                cls = label['cls'].reshape(-1).astype(int)\n",
    "                if cls.size == 0:\n",
    "                    weights.append(1)\n",
    "                    continue\n",
    "                weight = np.max(self.class_weights[cls])\n",
    "                weights.append(weight)\n",
    "            return weights\n",
    "\n",
    "        def calculate_probabilities(self):\n",
    "            \"\"\"Calculate sampling probabilities based on weights.\"\"\"\n",
    "            total_weight = sum(self.weights)\n",
    "            probabilities = [w / total_weight for w in self.weights]\n",
    "            return probabilities\n",
    "\n",
    "        def __getitem__(self, index):\n",
    "            \"\"\"\n",
    "            Get an item by sampling based on probabilities during training.\n",
    "\n",
    "            Args:\n",
    "                index (int): Index of the data.\n",
    "\n",
    "            Returns:\n",
    "                Tuple: Transformed image and labels.\n",
    "            \"\"\"\n",
    "            if not self.train_mode:\n",
    "                return self.transforms(self.get_image_and_label(index))\n",
    "            else:\n",
    "                sampled_index = np.random.choice(len(self.labels), p=self.probabilities)\n",
    "                return self.transforms(self.get_image_and_label(sampled_index))\n",
    "\n",
    "    # Apply the monkey-patch\n",
    "    build.YOLODataset = YOLOWeightedDataset\n",
    "    print(\"YOLODataset has been monkey-patched with YOLOWeightedDataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "659785af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.106727Z",
     "iopub.status.busy": "2024-09-24T10:51:58.106404Z",
     "iopub.status.idle": "2024-09-24T10:51:58.123482Z",
     "shell.execute_reply": "2024-09-24T10:51:58.122843Z"
    },
    "papermill": {
     "duration": 0.030046,
     "end_time": "2024-09-24T10:51:58.125318",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.095272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Define custom modules and loss functions\n",
    "# class DyReLU(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Dynamic ReLU activation function with adaptive coefficients.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, channels, reduction=4, k=2, conv_type='2d'):\n",
    "#         super(DyReLU, self).__init__()\n",
    "#         self.channels = channels\n",
    "#         self.k = k\n",
    "#         self.conv_type = conv_type\n",
    "#         assert self.conv_type in ['1d', '2d'], \"conv_type must be '1d' or '2d'\"\n",
    "\n",
    "#         self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "#         self.relu = nn.ReLU(inplace=True)\n",
    "#         self.fc2 = nn.Linear(channels // reduction, 2*k)\n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#         self.register_buffer('lambdas', torch.Tensor([1.]*k + [0.5]*k).float())\n",
    "#         self.register_buffer('init_v', torch.Tensor([1.] + [0.]*(2*k - 1)).float())\n",
    "\n",
    "#     def get_relu_coefs(self, x):\n",
    "#         theta = torch.mean(x, dim=-1)\n",
    "#         if self.conv_type == '2d':\n",
    "#             theta = torch.mean(theta, dim=-1)\n",
    "#         theta = self.fc1(theta)\n",
    "#         theta = self.relu(theta)\n",
    "#         theta = self.fc2(theta)\n",
    "#         theta = 2 * self.sigmoid(theta) - 1\n",
    "#         return theta\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         assert x.shape[1] == self.channels, f\"Expected input with {self.channels} channels, got {x.shape[1]}\"\n",
    "#         theta = self.get_relu_coefs(x)\n",
    "#         relu_coefs = theta.view(-1, self.channels, 2*self.k) * self.lambdas + self.init_v\n",
    "\n",
    "#         if self.conv_type == '2d':\n",
    "#             # (B, C, H, W) -> (B, C, H, W, 1)\n",
    "#             x_perm = x.unsqueeze(-1)\n",
    "#             output = x_perm * relu_coefs[:, :, :self.k] + relu_coefs[:, :, self.k:]\n",
    "#             result = torch.max(output, dim=-1)[0]\n",
    "#         else:\n",
    "#             # (B, C, L) -> (B, C, L, 1)\n",
    "#             x_perm = x.unsqueeze(-1)\n",
    "#             output = x_perm * relu_coefs[:, :, :self.k] + relu_coefs[:, :, self.k:]\n",
    "#             result = torch.max(output, dim=-1)[0]\n",
    "#         return result\n",
    "\n",
    "# class DMBottleneck(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Bottleneck module with OSRA, IDConv, and STE components.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c1, c2):\n",
    "#         super().__init__()\n",
    "#         self.split = nn.Sequential(\n",
    "#             nn.Conv2d(c1, c1 // 2, kernel_size=1, bias=False),\n",
    "#             nn.BatchNorm2d(c1 // 2),\n",
    "#             nn.SiLU()\n",
    "#         )\n",
    "#         self.osra = OSRA(c1 // 2, c2 // 2)\n",
    "#         self.idconv = IDConv(c1 // 2, c2 // 2)\n",
    "#         self.ste = STE(c2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1, x2 = self.split(x).chunk(2, dim=1)\n",
    "#         x1 = self.osra(x1)\n",
    "#         x2 = self.idconv(x2)\n",
    "#         x = torch.cat([x1, x2], dim=1)\n",
    "#         x = self.ste(x)\n",
    "#         return x\n",
    "\n",
    "# class OSRA(nn.Module):\n",
    "#     \"\"\"\n",
    "#     OSRA module for attention on spatial regions.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c1, c2):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.Conv2d(c1, c2, kernel_size=3, padding=1, bias=False)\n",
    "#         self.bn = nn.BatchNorm2d(c2)\n",
    "#         self.act = nn.SiLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.act(x)\n",
    "#         return x\n",
    "\n",
    "# class IDConv(nn.Module):\n",
    "#     \"\"\"\n",
    "#     IDConv module for identity-based convolution.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c1, c2, r=4):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(c1, c1 // r, kernel_size=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(c1 // r)\n",
    "#         self.act1 = nn.SiLU()\n",
    "#         self.conv2 = nn.Conv2d(c1 // r, c2, kernel_size=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(c2)\n",
    "#         self.act2 = nn.SiLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.act1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.act2(x)\n",
    "#         return x\n",
    "\n",
    "# class STE(nn.Module):\n",
    "#     \"\"\"\n",
    "#     STE module for shortcut and transformation.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c, r=4):\n",
    "#         super().__init__()\n",
    "#         self.conv1 = nn.Conv2d(c, c // r, kernel_size=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(c // r)\n",
    "#         self.act1 = nn.SiLU()\n",
    "#         self.conv2 = nn.Conv2d(c // r, c, kernel_size=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(c)\n",
    "#         self.act2 = nn.SiLU()\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         shortcut = x\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.act1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.act2(x)\n",
    "#         x = x + shortcut\n",
    "#         return x\n",
    "\n",
    "# class C2fDM(nn.Module):\n",
    "#     \"\"\"\n",
    "#     C2fDM module replacing C2f with customizable depth and shortcut.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):\n",
    "#         super().__init__()\n",
    "#         self.c = int(c2 * e)\n",
    "#         self.cv1 = nn.Conv2d(c1, 2 * self.c, kernel_size=1, bias=False)\n",
    "#         self.cv2 = nn.Conv2d((2 + n) * self.c, c2, kernel_size=1, bias=False)\n",
    "#         self.bn = nn.BatchNorm2d(2 * self.c)\n",
    "#         self.act = nn.SiLU()\n",
    "#         self.m = nn.Sequential(*(DMBottleneck(self.c, self.c) for _ in range(n)))\n",
    "#         self.shortcut = shortcut\n",
    "#         if self.shortcut:\n",
    "#             self.shortcut_conv = nn.Conv2d(c1, c2, kernel_size=1, bias=False)\n",
    "#             self.shortcut_bn = nn.BatchNorm2d(c2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         residual = x\n",
    "#         x = self.cv1(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.act(x)\n",
    "#         x1, x2 = x.chunk(2, dim=1)\n",
    "#         x2 = self.m(x2)\n",
    "#         x = torch.cat([x1, x2], dim=1)\n",
    "#         if self.shortcut:\n",
    "#             residual = self.shortcut_bn(self.shortcut_conv(residual))\n",
    "#             x = x + residual  # Perform correct addition\n",
    "#         x = self.cv2(x)\n",
    "#         return x\n",
    "\n",
    "# class BRA(nn.Module):\n",
    "#     \"\"\"\n",
    "#     BRA module for attention mechanisms focusing on important image regions.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c, num_regions=5, s=8):\n",
    "#         super().__init__()\n",
    "#         self.q = nn.Linear(c, c, bias=False)\n",
    "#         self.k = nn.Linear(c, c, bias=False)\n",
    "#         self.v = nn.Linear(c, c, bias=False)\n",
    "#         self.s = s\n",
    "#         self.num_regions = num_regions\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         b, c, h, w = x.shape\n",
    "#         x = x.reshape(b, c, -1).permute(0, 2, 1)  # (batch, seq_len, c)\n",
    "#         q = self.q(x)\n",
    "#         k = self.k(x)\n",
    "#         v = self.v(x)\n",
    "#         q = q.reshape(b, -1, self.s, c // self.s).permute(0, 2, 1, 3)\n",
    "#         k = k.reshape(b, -1, self.s, c // self.s).permute(0, 2, 3, 1)\n",
    "#         v = v.reshape(b, -1, self.s, c // self.s).permute(0, 2, 1, 3)\n",
    "#         attn = (q @ k.transpose(-2, -1)) * (1.0 / torch.sqrt(torch.tensor(k.size(-1), dtype=torch.float32)))\n",
    "#         attn = attn.softmax(dim=-1)\n",
    "#         x = (attn @ v).transpose(1, 2).reshape(b, h, w, c)\n",
    "#         x = x.permute(0, 3, 1, 2)\n",
    "#         return x\n",
    "\n",
    "# class BGFPN(nn.Module):\n",
    "#     \"\"\"\n",
    "#     BGFPN module utilizing BRA to enhance multi-scale processing capabilities.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c1_list, c2, n=1, shortcut=False, g=1, e=0.5):\n",
    "#         super().__init__()\n",
    "#         total_c1 = sum(c1_list)\n",
    "#         self.cv1 = nn.Conv2d(total_c1, c2, kernel_size=1, bias=False)\n",
    "#         self.bn1 = nn.BatchNorm2d(c2)\n",
    "#         self.act1 = nn.SiLU()\n",
    "#         self.cv2 = nn.Conv2d(c2, c2, kernel_size=3, padding=1, bias=False)\n",
    "#         self.bn2 = nn.BatchNorm2d(c2)\n",
    "#         self.act2 = nn.SiLU()\n",
    "#         self.bra = BRA(c2)\n",
    "#         self.m = nn.Sequential(*(C2fDM(c2, c2, n, shortcut, g, e) for _ in range(n)))\n",
    "\n",
    "#     def forward(self, *inputs):\n",
    "#         \"\"\"\n",
    "#         Forward pass for BGFPN.\n",
    "\n",
    "#         Args:\n",
    "#             *inputs: Variable number of input feature maps.\n",
    "\n",
    "#         Returns:\n",
    "#             Tensor: Output feature map after processing.\n",
    "#         \"\"\"\n",
    "#         x = torch.cat(inputs, dim=1)\n",
    "#         x = self.cv1(x)\n",
    "#         x = self.bn1(x)\n",
    "#         x = self.act1(x)\n",
    "#         x = self.cv2(x)\n",
    "#         x = self.bn2(x)\n",
    "#         x = self.act2(x)\n",
    "#         x = self.bra(x)\n",
    "#         x = self.m(x)\n",
    "#         return x\n",
    "\n",
    "# class SMPDIoU(nn.Module):\n",
    "#     \"\"\"\n",
    "#     SMPDIoU loss function for optimizing bounding box regression.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, alpha=0.5):\n",
    "#         super().__init__()\n",
    "#         self.alpha = alpha\n",
    "\n",
    "#     def forward(self, pred, target):\n",
    "#         \"\"\"\n",
    "#         Compute the SMPDIoU loss between predicted and target bounding boxes.\n",
    "\n",
    "#         Args:\n",
    "#             pred (Tensor): Predicted bounding boxes with shape (N, 4).\n",
    "#             target (Tensor): Ground truth bounding boxes with shape (N, 4).\n",
    "\n",
    "#         Returns:\n",
    "#             Tensor: Scalar loss value.\n",
    "#         \"\"\"\n",
    "#         # Split bounding box components\n",
    "#         pred_left, pred_top, pred_right, pred_bottom = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]\n",
    "#         target_left, target_top, target_right, target_bottom = target[:, 0], target[:, 1], target[:, 2], target[:, 3]\n",
    "\n",
    "#         # Compute areas\n",
    "#         target_area = (target_left + target_right) * (target_top + target_bottom)\n",
    "#         pred_area = (pred_left + pred_right) * (pred_top + pred_bottom)\n",
    "\n",
    "#         # Compute intersection areas\n",
    "#         w_intersect = torch.min(pred_left, target_left) + torch.min(pred_right, target_right)\n",
    "#         h_intersect = torch.min(pred_bottom, target_bottom) + torch.min(pred_top, target_top)\n",
    "#         area_intersect = w_intersect * h_intersect\n",
    "#         area_union = target_area + pred_area - area_intersect\n",
    "#         iou = area_intersect / area_union\n",
    "\n",
    "#         # Compute additional loss components\n",
    "#         delta_w = torch.abs(pred_left - target_left) + torch.abs(pred_right - target_right)\n",
    "#         delta_h = torch.abs(pred_top - target_top) + torch.abs(pred_bottom - target_bottom)\n",
    "#         distance_loss = torch.sum(1 - torch.exp(-delta_w)) + torch.sum(1 - torch.exp(-delta_h))\n",
    "\n",
    "#         omega_w = (torch.abs(pred_left - target_left) + torch.abs(pred_right - target_right)) / torch.max(pred_left + pred_right, target_left + target_right)\n",
    "#         omega_h = (torch.abs(pred_top - target_top) + torch.abs(pred_bottom - target_bottom)) / torch.max(pred_top + pred_bottom, target_top + target_bottom)\n",
    "#         shape_loss = torch.sum(1 - torch.exp(-omega_w ** 4)) + torch.sum(1 - torch.exp(-omega_h ** 4))\n",
    "\n",
    "#         # Compute perpendicular distance\n",
    "#         pred_center_x = (pred_left + pred_right) / 2\n",
    "#         pred_center_y = (pred_top + pred_bottom) / 2\n",
    "#         target_center_x = (target_left + target_right) / 2\n",
    "#         target_center_y = (target_top + target_bottom) / 2\n",
    "\n",
    "#         perpendicular_distance = torch.sqrt((pred_center_x - target_center_x) ** 2 + (pred_center_y - target_center_y) ** 2)\n",
    "#         max_distance = torch.sqrt(target_left ** 2 + target_top ** 2)\n",
    "#         normalized_distance = perpendicular_distance / max_distance\n",
    "\n",
    "#         # Compute SMPDIoU loss\n",
    "#         smpdiou = self.alpha * (1 - iou) + (1 - self.alpha) * (distance_loss + shape_loss)\n",
    "#         smpdiou = torch.clamp(smpdiou, min=0)  # Ensure non-negative\n",
    "#         return smpdiou.mean()\n",
    "\n",
    "# class Fusion(nn.Module):\n",
    "#     \"\"\"\n",
    "#     Fusion module to replace Concat, combining two feature maps.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c1, c2):\n",
    "#         super().__init__()\n",
    "#         self.conv = nn.Conv2d(c1 + c2, c2, kernel_size=1, bias=False)\n",
    "#         self.bn = nn.BatchNorm2d(c2)\n",
    "#         self.act = nn.SiLU()\n",
    "\n",
    "#     def forward(self, x1, x2):\n",
    "#         \"\"\"\n",
    "#         Forward pass for Fusion.\n",
    "\n",
    "#         Args:\n",
    "#             x1 (Tensor): First input feature map.\n",
    "#             x2 (Tensor): Second input feature map.\n",
    "\n",
    "#         Returns:\n",
    "#             Tensor: Combined feature map after convolution and activation.\n",
    "#         \"\"\"\n",
    "#         x = torch.cat([x1, x2], dim=1)\n",
    "#         x = self.conv(x)\n",
    "#         x = self.bn(x)\n",
    "#         x = self.act(x)\n",
    "#         return x\n",
    "\n",
    "# class BiFormer(nn.Module):\n",
    "#     \"\"\"\n",
    "#     BiFormer module for attention mechanisms.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, c):\n",
    "#         super().__init__()\n",
    "#         self.attn = nn.MultiheadAttention(c, num_heads=8, batch_first=True)\n",
    "#         self.ln = nn.LayerNorm(c)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"\n",
    "#         Forward pass for BiFormer.\n",
    "\n",
    "#         Args:\n",
    "#             x (Tensor): Input feature map with shape (B, C, H, W).\n",
    "\n",
    "#         Returns:\n",
    "#             Tensor: Output feature map after attention and normalization.\n",
    "#         \"\"\"\n",
    "#         b, c, h, w = x.shape\n",
    "#         x_flat = x.view(b, c, -1).permute(0, 2, 1)  # (B, L, C)\n",
    "#         attn_output, _ = self.attn(x_flat, x_flat, x_flat)\n",
    "#         attn_output = self.ln(attn_output + x_flat)\n",
    "#         x = attn_output.permute(0, 2, 1).view(b, c, h, w)\n",
    "#         return x\n",
    "\n",
    "# # Helper functions to get in/out channels\n",
    "# def get_out_channels(layer):\n",
    "#     \"\"\"\n",
    "#     Recursively get the number of output channels for a given layer.\n",
    "\n",
    "#     Args:\n",
    "#         layer (nn.Module): The layer to inspect.\n",
    "\n",
    "#     Returns:\n",
    "#         int: Number of output channels.\n",
    "#     \"\"\"\n",
    "#     if hasattr(layer, 'out_channels'):\n",
    "#         return layer.out_channels\n",
    "#     elif hasattr(layer, 'conv'):\n",
    "#         return layer.conv.out_channels\n",
    "#     elif hasattr(layer, 'conv2d'):\n",
    "#         return layer.conv2d.out_channels\n",
    "#     elif hasattr(layer, 'cv2'):\n",
    "#         return get_out_channels(layer.cv2)\n",
    "#     elif hasattr(layer, 'cv'):\n",
    "#         return get_out_channels(layer.cv)\n",
    "#     else:\n",
    "#         for sublayer in reversed(list(layer.children())):\n",
    "#             out_channels = get_out_channels(sublayer)\n",
    "#             if out_channels > 0:\n",
    "#                 return out_channels\n",
    "#         return 0\n",
    "\n",
    "# def get_in_channels(layer):\n",
    "#     \"\"\"\n",
    "#     Recursively get the number of input channels for a given layer.\n",
    "\n",
    "#     Args:\n",
    "#         layer (nn.Module): The layer to inspect.\n",
    "\n",
    "#     Returns:\n",
    "#         int: Number of input channels.\n",
    "#     \"\"\"\n",
    "#     if hasattr(layer, 'in_channels'):\n",
    "#         return layer.in_channels\n",
    "#     elif hasattr(layer, 'conv'):\n",
    "#         return layer.conv.in_channels\n",
    "#     elif hasattr(layer, 'conv2d'):\n",
    "#         return layer.conv2d.in_channels\n",
    "#     elif hasattr(layer, 'cv1'):\n",
    "#         return get_in_channels(layer.cv1)\n",
    "#     elif hasattr(layer, 'cv'):\n",
    "#         return get_in_channels(layer.cv)\n",
    "#     else:\n",
    "#         for sublayer in list(layer.children()):\n",
    "#             in_channels = get_in_channels(sublayer)\n",
    "#             if in_channels > 0:\n",
    "#                 return in_channels\n",
    "#         return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0ec66b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.146143Z",
     "iopub.status.busy": "2024-09-24T10:51:58.145859Z",
     "iopub.status.idle": "2024-09-24T10:51:58.155285Z",
     "shell.execute_reply": "2024-09-24T10:51:58.154474Z"
    },
    "papermill": {
     "duration": 0.021992,
     "end_time": "2024-09-24T10:51:58.157101",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.135109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Main HPYOLOv8 class with custom modifications\n",
    "# class HPYOLOv8(nn.Module):\n",
    "#     \"\"\"\n",
    "#     HPYOLOv8 class that extends the YOLOv8 model with custom modifications.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, model_path='yolov8x.pt'):\n",
    "#         super().__init__()\n",
    "#         self.model = YOLO(model_path)\n",
    "\n",
    "#         # Ensure that the DyReLU activation is correctly replacing SiLU\n",
    "#         for name, module in model.model.model.named_modules():\n",
    "#             if isinstance(module, nn.SiLU):\n",
    "#                 parent_name = '.'.join(name.split('.')[:-1])\n",
    "#                 layer_name = name.split('.')[-1]\n",
    "#                 parent = model.model.model\n",
    "#                 if parent_name:\n",
    "#                     for n in parent_name.split('.'):\n",
    "#                         parent = getattr(parent, n)\n",
    "#                 if hasattr(parent, 'conv'):\n",
    "#                     out_channels = parent.conv.out_channels\n",
    "#                     new_act = DyReLU(out_channels)\n",
    "#                     setattr(parent, layer_name, new_act)\n",
    "#                     print(f\"Replaced SiLU with DyReLU in layer: {name}\")\n",
    "#                 else:\n",
    "#                     print(f\"Skipped replacement for layer: {name} (no 'conv' attribute)\")\n",
    "\n",
    "#         # Replace C2f with C2fDM in Backbone\n",
    "#         for i, layer in enumerate(self.model.model.model):\n",
    "#             if isinstance(layer, nn.Sequential):\n",
    "#                 for j, sublayer in enumerate(layer):\n",
    "#                     if type(sublayer).__name__ == \"C2f\":\n",
    "#                         print(f\"Layer {i}.{j} is C2f, replacing with C2fDM.\")\n",
    "#                         c1 = sublayer.cv1.conv.in_channels if hasattr(sublayer, 'cv1') and hasattr(sublayer.cv1, 'conv') else get_in_channels(sublayer.cv1)\n",
    "#                         c2 = sublayer.cv2.conv.out_channels if hasattr(sublayer, 'cv2') and hasattr(sublayer.cv2, 'conv') else get_out_channels(sublayer.cv2)\n",
    "#                         c2fdm = C2fDM(c1, c2)\n",
    "#                         self.model.model.model[i][j] = c2fdm\n",
    "#                         print(f\"Replaced C2f with C2fDM in layer {i}.{j}.\")\n",
    "#             elif type(layer).__name__ == \"C2f\":\n",
    "#                 print(f\"Layer {i} is C2f, replacing with C2fDM.\")\n",
    "#                 c1 = layer.cv1.conv.in_channels if hasattr(layer, 'cv1') and hasattr(layer.cv1, 'conv') else get_in_channels(layer.cv1)\n",
    "#                 c2 = layer.cv2.conv.out_channels if hasattr(layer, 'cv2') and hasattr(layer.cv2, 'conv') else get_out_channels(layer.cv2)\n",
    "#                 c2fdm = C2fDM(c1, c2)\n",
    "#                 self.model.model.model[i] = c2fdm\n",
    "#                 print(f\"Replaced C2f with C2fDM in layer {i}.\")\n",
    "\n",
    "#         # Replace Concat with Fusion and add BiFormer in Neck\n",
    "#         i = 0\n",
    "#         while i < len(self.model.model.model):\n",
    "#             layer = self.model.model.model[i]\n",
    "#             if type(layer).__name__ == \"Concat\":\n",
    "#                 print(f\"Layer {i} is Concat, replacing with Fusion and adding BiFormer.\")\n",
    "#                 c1 = 0\n",
    "#                 for idx in layer.f:\n",
    "#                     if idx < len(self.model.model.model):\n",
    "#                         prev_layer = self.model.model.model[idx]\n",
    "#                         out_channels = get_out_channels(prev_layer)\n",
    "#                         c1 += out_channels\n",
    "#                     else:\n",
    "#                         print(f\"Invalid layer index {idx} in Concat layer {i}. Skipping.\")\n",
    "#                 if i + 1 < len(self.model.model.model):\n",
    "#                     next_layer = self.model.model.model[i + 1]\n",
    "#                     c2 = get_in_channels(next_layer)\n",
    "#                 else:\n",
    "#                     c2 = c1\n",
    "#                 fusion_layer = Fusion(c1, c2)\n",
    "#                 biformer_layer = BiFormer(c1)\n",
    "#                 # Replace Concat with BiFormer and Fusion\n",
    "#                 self.model.model.model[i] = nn.Sequential(biformer_layer, fusion_layer)\n",
    "#                 print(f\"Replaced layer {i} with BiFormer and Fusion.\")\n",
    "#                 i += 1\n",
    "#             else:\n",
    "#                 i += 1\n",
    "\n",
    "#         # Replace FPN with BGFPN\n",
    "#         try:\n",
    "#             detect_layer = self.model.model.model[-1]\n",
    "#             in_channels_list = [detect_layer.cv2[i][0].conv.in_channels for i in range(3)]\n",
    "#             in_channels_list.insert(0, self.model.model.model[-4].conv.out_channels)\n",
    "#             out_channels = detect_layer.cv2[0][-1].conv.out_channels if hasattr(detect_layer.cv2[0][-1], 'conv') else get_out_channels(detect_layer.cv2[0][-1])\n",
    "#             bgfpn = BGFPN(in_channels_list, out_channels)\n",
    "#             self.model.model.model[-1] = bgfpn\n",
    "#             print(\"Replaced FPN with BGFPN.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to replace FPN with BGFPN: {e}\")\n",
    "\n",
    "#         # Replace CIoU Loss with SMPDIoU and add CBFocalLoss\n",
    "#         try:\n",
    "#             self.model.model.model[-1].loss = SMPDIoU(alpha=0.75)  # Replace CIoU with SMPDIoU\n",
    "#             self.focal_loss = CBFocalLoss(weights)  # Add CBFocalLoss\n",
    "#             print(\"Replaced CIoU loss with SMPDIoU and added CBFocalLoss.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"Failed to replace loss functions: {e}\")\n",
    "            \n",
    "\n",
    "#         # Verify that Fusion and BiFormer are correctly integrated\n",
    "#         for i, layer in enumerate(model.model.model):\n",
    "#             if isinstance(layer, Fusion) or isinstance(layer, BiFormer):\n",
    "#                 print(f\"Layer {i} is correctly replaced with {type(layer).__name__}\")\n",
    "\n",
    "#     def add_callback(self, event, func):\n",
    "#         \"\"\"\n",
    "#         Forward the add_callback method to the internal YOLO model.\n",
    "\n",
    "#         Args:\n",
    "#             event (str): The event to attach the callback to.\n",
    "#             func (callable): The callback function.\n",
    "#         \"\"\"\n",
    "#         if hasattr(self.model, 'add_callback'):\n",
    "#             self.model.add_callback(event, func)\n",
    "#             print(f\"Added callback for event '{event}'.\")\n",
    "#         else:\n",
    "#             raise AttributeError(f\"'YOLO' object has no attribute 'add_callback'\")\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"Forward pass through the YOLO model.\"\"\"\n",
    "#         return self.model(x)\n",
    "\n",
    "#     def train_model(self, **kwargs):\n",
    "#         \"\"\"Train the YOLO model with given parameters.\"\"\"\n",
    "#         return self.model.train(**kwargs)\n",
    "\n",
    "#     def val(self, **kwargs):\n",
    "#         \"\"\"Validate the YOLO model with given parameters.\"\"\"\n",
    "#         return self.model.val(**kwargs)\n",
    "    \n",
    "#     def compute_loss(self, pred_boxes, gt_boxes, pred_classes, gt_classes):\n",
    "#         \"\"\"\n",
    "#         Compute the combined SMPDIoU and CBFocalLoss.\n",
    "\n",
    "#         Args:\n",
    "#             pred_boxes (Tensor): Predicted bounding boxes.\n",
    "#             gt_boxes (Tensor): Ground truth bounding boxes.\n",
    "#             pred_classes (Tensor): Predicted class logits.\n",
    "#             gt_classes (Tensor): Ground truth class indices.\n",
    "\n",
    "#         Returns:\n",
    "#             Tensor: Combined loss value.\n",
    "#         \"\"\"\n",
    "#         # Combine box loss (SMPDIoU) and classification loss (CBFocalLoss)\n",
    "#         box_loss = self.model.model.model[-1].loss(pred_boxes, gt_boxes)\n",
    "\n",
    "#         # Compute classification loss\n",
    "#         class_loss = self.focal_loss(pred_classes, gt_classes)\n",
    "#         total_loss = box_loss + class_loss\n",
    "\n",
    "#         # Check if loss is negative\n",
    "#         if total_loss.item() < 0:\n",
    "#             print(\"Warning: Loss is negative\")\n",
    "\n",
    "#         return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e35c94b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.177866Z",
     "iopub.status.busy": "2024-09-24T10:51:58.177576Z",
     "iopub.status.idle": "2024-09-24T10:51:58.242486Z",
     "shell.execute_reply": "2024-09-24T10:51:58.241798Z"
    },
    "papermill": {
     "duration": 0.077461,
     "end_time": "2024-09-24T10:51:58.244251",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.166790",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define custom modules and loss functions\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DyReLU(nn.Module):\n",
    "    \"\"\"\n",
    "    Dynamic ReLU activation function with adaptive coefficients.\n",
    "    \"\"\"\n",
    "    def __init__(self, channels, reduction=4, k=2, conv_type='2d'):\n",
    "        super(DyReLU, self).__init__()\n",
    "        self.channels = channels\n",
    "        self.k = k\n",
    "        self.conv_type = conv_type\n",
    "        assert self.conv_type in ['1d', '2d'], \"conv_type must be '1d' or '2d'\"\n",
    "\n",
    "        # Định nghĩa các lớp Linear với kích thước đúng\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)          # Nhận đầu vào C, trả về C//reduction\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels * 2 * k)  # Nhận đầu vào C//reduction, trả về C * 2 * k\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "        # Các hệ số cố định\n",
    "        self.register_buffer('lambdas', torch.Tensor([1.]*k + [0.5]*k).float())\n",
    "        self.register_buffer('init_v', torch.Tensor([1.] + [0.]*(2*k - 1)).float())\n",
    "\n",
    "    def get_relu_coefs(self, x):\n",
    "        \"\"\"\n",
    "        Tính toán các hệ số ReLU dựa trên đầu vào.\n",
    "        \"\"\"\n",
    "        if self.conv_type == '2d':\n",
    "            theta = torch.mean(x, dim=(2, 3))  # Trung bình theo chiều H và W: (B, C)\n",
    "        else:\n",
    "            theta = torch.mean(x, dim=-1)      # Trung bình theo chiều L: (B, C)\n",
    "        theta = self.fc1(theta)               # (B, C//reduction)\n",
    "        theta = self.relu(theta)              # (B, C//reduction)\n",
    "        theta = self.fc2(theta)               # (B, C * 2 * k)\n",
    "        theta = 2 * self.sigmoid(theta) - 1   # (B, C * 2 * k)\n",
    "        return theta\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass của DyReLU.\n",
    "        \"\"\"\n",
    "        # Kiểm tra số kênh\n",
    "        assert x.shape[1] == self.channels, f\"Expected input with {self.channels} channels, got {x.shape[1]}\"\n",
    "        \n",
    "        # Tính các hệ số ReLU\n",
    "        theta = self.get_relu_coefs(x)  # (B, C * 2 * k)\n",
    "        \n",
    "        # Reshape để phù hợp với từng kênh\n",
    "        relu_coefs = theta.view(-1, self.channels, 2 * self.k) * self.lambdas + self.init_v  # (B, C, 2*k)\n",
    "\n",
    "        if self.conv_type == '2d':\n",
    "            # (B, C, H, W) -> (B, C, H, W, 1)\n",
    "            x_perm = x.unsqueeze(-1)  # (B, C, H, W, 1)\n",
    "            # Broadcast relu_coefs tới các chiều không gian\n",
    "            relu_coefs = relu_coefs.unsqueeze(2).unsqueeze(3)  # (B, C, 1, 1, 2*k)\n",
    "            # Tính toán phần tích và cộng\n",
    "            output = x_perm * relu_coefs[:, :, :, :, :self.k] + relu_coefs[:, :, :, :, self.k:]\n",
    "            # Lấy giá trị lớn nhất theo chiều cuối cùng\n",
    "            result = torch.max(output, dim=-1)[0]  # (B, C, H, W)\n",
    "        else:\n",
    "            # (B, C, L) -> (B, C, L, 1)\n",
    "            x_perm = x.unsqueeze(-1)  # (B, C, L, 1)\n",
    "            relu_coefs = relu_coefs.unsqueeze(2)  # (B, C, 1, 2*k)\n",
    "            output = x_perm * relu_coefs[:, :, :, :self.k] + relu_coefs[:, :, :, self.k:]\n",
    "            result = torch.max(output, dim=-1)[0]  # (B, C, L)\n",
    "        return result\n",
    "\n",
    "class DMBottleneck(nn.Module):\n",
    "    \"\"\"\n",
    "    Bottleneck module with OSRA, IDConv, and STE components.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.split = nn.Sequential(\n",
    "            nn.Conv2d(c1, c1 // 2, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(c1 // 2),\n",
    "            DyReLU(c1 // 2)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "        )\n",
    "        self.osra = OSRA(c1 // 2, c2 // 2)\n",
    "        self.idconv = IDConv(c1 // 2, c2 // 2)\n",
    "        self.ste = STE(c2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1, x2 = self.split(x).chunk(2, dim=1)\n",
    "        x1 = self.osra(x1)\n",
    "        x2 = self.idconv(x2)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.ste(x)\n",
    "        return x\n",
    "\n",
    "class OSRA(nn.Module):\n",
    "    \"\"\"\n",
    "    OSRA module for attention on spatial regions.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1, c2, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = DyReLU(c2)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class IDConv(nn.Module):\n",
    "    \"\"\"\n",
    "    IDConv module for identity-based convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2, r=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c1, c1 // r, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c1 // r)\n",
    "        self.act1 = DyReLU(c1 // r)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "        self.conv2 = nn.Conv2d(c1 // r, c2, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c2)\n",
    "        self.act2 = DyReLU(c2)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        return x\n",
    "\n",
    "class STE(nn.Module):\n",
    "    \"\"\"\n",
    "    STE module for shortcut and transformation.\n",
    "    \"\"\"\n",
    "    def __init__(self, c, r=4):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(c, c // r, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c // r)\n",
    "        self.act1 = DyReLU(c // r)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "        self.conv2 = nn.Conv2d(c // r, c, kernel_size=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c)\n",
    "        self.act2 = DyReLU(c)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "\n",
    "    def forward(self, x):\n",
    "        shortcut = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = x + shortcut\n",
    "        return x\n",
    "\n",
    "class C2fDM(nn.Module):\n",
    "    \"\"\"\n",
    "    C2fDM module replacing C2f with customizable depth and shortcut.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5, f=-1):\n",
    "        super().__init__()\n",
    "        self.f = f  # Thêm thuộc tính 'f'\n",
    "        self.c = int(c2 * e)\n",
    "        self.cv1 = nn.Conv2d(c1, 2 * self.c, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(2 * self.c)\n",
    "        self.act = DyReLU(2 * self.c)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "        self.cv2 = nn.Conv2d((2 + n) * self.c, c2, kernel_size=1, bias=False)\n",
    "        self.m = nn.Sequential(*(DMBottleneck(self.c, self.c) for _ in range(n)))\n",
    "        self.shortcut = shortcut\n",
    "        if self.shortcut:\n",
    "            self.shortcut_conv = nn.Conv2d(c1, c2, kernel_size=1, bias=False)\n",
    "            self.shortcut_bn = nn.BatchNorm2d(c2)\n",
    "            self.shortcut_act = DyReLU(c2)  # Thêm DyReLU cho shortcut\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.cv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        x2 = self.m(x2)\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        if self.shortcut:\n",
    "            residual = self.shortcut_conv(residual)\n",
    "            residual = self.shortcut_bn(residual)\n",
    "            residual = self.shortcut_act(residual)  # Áp dụng DyReLU cho shortcut\n",
    "            x = x + residual  # Thực hiện phép cộng đúng cách\n",
    "        x = self.cv2(x)\n",
    "        return x\n",
    "\n",
    "class BRA(nn.Module):\n",
    "    \"\"\"\n",
    "    BRA module for attention mechanisms focusing on important image regions.\n",
    "    \"\"\"\n",
    "    def __init__(self, c, num_regions=5, s=8):\n",
    "        super().__init__()\n",
    "        self.q = nn.Linear(c, c, bias=False)\n",
    "        self.k = nn.Linear(c, c, bias=False)\n",
    "        self.v = nn.Linear(c, c, bias=False)\n",
    "        self.s = s\n",
    "        self.num_regions = num_regions\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.shape\n",
    "        x = x.reshape(b, c, -1).permute(0, 2, 1)  # (batch, seq_len, c)\n",
    "        q = self.q(x)\n",
    "        k = self.k(x)\n",
    "        v = self.v(x)\n",
    "        q = q.reshape(b, -1, self.s, c // self.s).permute(0, 2, 1, 3)\n",
    "        k = k.reshape(b, -1, self.s, c // self.s).permute(0, 2, 3, 1)\n",
    "        v = v.reshape(b, -1, self.s, c // self.s).permute(0, 2, 1, 3)\n",
    "        attn = (q @ k.transpose(-2, -1)) * (1.0 / torch.sqrt(torch.tensor(k.size(-1), dtype=torch.float32)))\n",
    "        attn = attn.softmax(dim=-1)\n",
    "        x = (attn @ v).transpose(1, 2).reshape(b, h, w, c)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        return x\n",
    "\n",
    "class BGFPN(nn.Module):\n",
    "    \"\"\"\n",
    "    BGFPN module utilizing BRA to enhance multi-scale processing capabilities.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1_list, c2, n=1, shortcut=False, g=1, e=0.5):\n",
    "        super().__init__()\n",
    "        total_c1 = sum(c1_list)\n",
    "        self.cv1 = nn.Conv2d(total_c1, c2, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(c2)\n",
    "        self.act1 = DyReLU(c2)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "        self.cv2 = nn.Conv2d(c2, c2, kernel_size=3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(c2)\n",
    "        self.act2 = DyReLU(c2)  # Thay thế nn.SiLU() bằng DyReLU\n",
    "        self.bra = BRA(c2)\n",
    "        self.m = nn.Sequential(*(C2fDM(c2, c2, n, shortcut, g, e) for _ in range(n)))\n",
    "\n",
    "    def forward(self, *inputs):\n",
    "        \"\"\"\n",
    "        Forward pass for BGFPN.\n",
    "\n",
    "        Args:\n",
    "            *inputs: Variable number of input feature maps.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output feature map after processing.\n",
    "        \"\"\"\n",
    "        x = torch.cat(inputs, dim=1)\n",
    "        x = self.cv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.act1(x)\n",
    "        x = self.cv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.act2(x)\n",
    "        x = self.bra(x)\n",
    "        x = self.m(x)\n",
    "        return x\n",
    "\n",
    "class SMPDIoU(nn.Module):\n",
    "    \"\"\"\n",
    "    SMPDIoU loss function for optimizing bounding box regression.\n",
    "    \"\"\"\n",
    "    def __init__(self, alpha=0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        Compute the SMPDIoU loss between predicted and target bounding boxes.\n",
    "\n",
    "        Args:\n",
    "            pred (Tensor): Predicted bounding boxes with shape (N, 4).\n",
    "            target (Tensor): Ground truth bounding boxes with shape (N, 4).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Scalar loss value.\n",
    "        \"\"\"\n",
    "        # Split bounding box components\n",
    "        pred_left, pred_top, pred_right, pred_bottom = pred[:, 0], pred[:, 1], pred[:, 2], pred[:, 3]\n",
    "        target_left, target_top, target_right, target_bottom = target[:, 0], target[:, 1], target[:, 2], target[:, 3]\n",
    "\n",
    "        # Compute areas\n",
    "        target_area = (target_left + target_right) * (target_top + target_bottom)\n",
    "        pred_area = (pred_left + pred_right) * (pred_top + pred_bottom)\n",
    "\n",
    "        # Compute intersection areas\n",
    "        w_intersect = torch.min(pred_left, target_left) + torch.min(pred_right, target_right)\n",
    "        h_intersect = torch.min(pred_bottom, target_bottom) + torch.min(pred_top, target_top)\n",
    "        area_intersect = w_intersect * h_intersect\n",
    "        area_union = target_area + pred_area - area_intersect\n",
    "        iou = area_intersect / area_union\n",
    "\n",
    "        # Compute additional loss components\n",
    "        delta_w = torch.abs(pred_left - target_left) + torch.abs(pred_right - target_right)\n",
    "        delta_h = torch.abs(pred_top - target_top) + torch.abs(pred_bottom - target_bottom)\n",
    "        distance_loss = torch.sum(1 - torch.exp(-delta_w)) + torch.sum(1 - torch.exp(-delta_h))\n",
    "\n",
    "        omega_w = (torch.abs(pred_left - target_left) + torch.abs(pred_right - target_right)) / torch.max(pred_left + pred_right, target_left + target_right)\n",
    "        omega_h = (torch.abs(pred_top - target_top) + torch.abs(pred_bottom - target_bottom)) / torch.max(pred_top + pred_bottom, target_top + target_bottom)\n",
    "        shape_loss = torch.sum(1 - torch.exp(-omega_w ** 4)) + torch.sum(1 - torch.exp(-omega_h ** 4))\n",
    "\n",
    "        # Compute perpendicular distance\n",
    "        pred_center_x = (pred_left + pred_right) / 2\n",
    "        pred_center_y = (pred_top + pred_bottom) / 2\n",
    "        target_center_x = (target_left + target_right) / 2\n",
    "        target_center_y = (target_top + target_bottom) / 2\n",
    "\n",
    "        perpendicular_distance = torch.sqrt((pred_center_x - target_center_x) ** 2 + (pred_center_y - target_center_y) ** 2)\n",
    "        max_distance = torch.sqrt(target_left ** 2 + target_top ** 2)\n",
    "        normalized_distance = perpendicular_distance / max_distance\n",
    "\n",
    "        # Compute SMPDIoU loss\n",
    "        smpdiou = self.alpha * (1 - iou) + (1 - self.alpha) * (distance_loss + shape_loss)\n",
    "        smpdiou = torch.clamp(smpdiou, min=0)  # Ensure non-negative\n",
    "        return smpdiou.mean()\n",
    "\n",
    "class Fusion(nn.Module):\n",
    "    \"\"\"\n",
    "    Fusion module to replace Concat, combining two feature maps.\n",
    "    \"\"\"\n",
    "    def __init__(self, c1, c2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(c1 + c2, c2, kernel_size=1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(c2)\n",
    "        self.act = DyReLU(c2, reduction=4, k=2, conv_type='2d')  # Thay thế nn.SiLU bằng DyReLU\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        \"\"\"\n",
    "        Forward pass for Fusion.\n",
    "\n",
    "        Args:\n",
    "            x1 (Tensor): First input feature map.\n",
    "            x2 (Tensor): Second input feature map.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Combined feature map after convolution and activation.\n",
    "        \"\"\"\n",
    "        x = torch.cat([x1, x2], dim=1)\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class BiFormer(nn.Module):\n",
    "    \"\"\"\n",
    "    BiFormer module for attention mechanisms.\n",
    "    \"\"\"\n",
    "    def __init__(self, c):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(c, num_heads=8, batch_first=True)\n",
    "        self.ln = nn.LayerNorm(c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for BiFormer.\n",
    "\n",
    "        Args:\n",
    "            x (Tensor): Input feature map with shape (B, C, H, W).\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Output feature map after attention and normalization.\n",
    "        \"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        x_flat = x.view(b, c, -1).permute(0, 2, 1)  # (B, L, C)\n",
    "        attn_output, _ = self.attn(x_flat, x_flat, x_flat)\n",
    "        attn_output = self.ln(attn_output + x_flat)\n",
    "        x = attn_output.permute(0, 2, 1).view(b, c, h, w)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1066f3bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.264740Z",
     "iopub.status.busy": "2024-09-24T10:51:58.264451Z",
     "iopub.status.idle": "2024-09-24T10:51:58.273680Z",
     "shell.execute_reply": "2024-09-24T10:51:58.272839Z"
    },
    "papermill": {
     "duration": 0.021566,
     "end_time": "2024-09-24T10:51:58.275509",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.253943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helper functions to get in/out channels\n",
    "def get_out_channels(layer):\n",
    "    \"\"\"\n",
    "    Recursively get the number of output channels for a given layer.\n",
    "\n",
    "    Args:\n",
    "        layer (nn.Module): The layer to inspect.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of output channels.\n",
    "    \"\"\"\n",
    "    if hasattr(layer, 'out_channels'):\n",
    "        return layer.out_channels\n",
    "    elif hasattr(layer, 'conv'):\n",
    "        return layer.conv.out_channels\n",
    "    elif hasattr(layer, 'conv2d'):\n",
    "        return layer.conv2d.out_channels\n",
    "    elif hasattr(layer, 'cv2'):\n",
    "        return get_out_channels(layer.cv2)\n",
    "    elif hasattr(layer, 'cv'):\n",
    "        return get_out_channels(layer.cv)\n",
    "    else:\n",
    "        for sublayer in reversed(list(layer.children())):\n",
    "            out_channels = get_out_channels(sublayer)\n",
    "            if out_channels > 0:\n",
    "                return out_channels\n",
    "        return 0\n",
    "\n",
    "def get_in_channels(layer):\n",
    "    \"\"\"\n",
    "    Recursively get the number of input channels for a given layer.\n",
    "\n",
    "    Args:\n",
    "        layer (nn.Module): The layer to inspect.\n",
    "\n",
    "    Returns:\n",
    "        int: Number of input channels.\n",
    "    \"\"\"\n",
    "    if hasattr(layer, 'in_channels'):\n",
    "        return layer.in_channels\n",
    "    elif hasattr(layer, 'conv'):\n",
    "        return layer.conv.in_channels\n",
    "    elif hasattr(layer, 'conv2d'):\n",
    "        return layer.conv2d.in_channels\n",
    "    elif hasattr(layer, 'cv1'):\n",
    "        return get_in_channels(layer.cv1)\n",
    "    elif hasattr(layer, 'cv'):\n",
    "        return get_in_channels(layer.cv)\n",
    "    else:\n",
    "        for sublayer in list(layer.children()):\n",
    "            in_channels = get_in_channels(sublayer)\n",
    "            if in_channels > 0:\n",
    "                return in_channels\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9138384e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.296155Z",
     "iopub.status.busy": "2024-09-24T10:51:58.295870Z",
     "iopub.status.idle": "2024-09-24T10:51:58.302218Z",
     "shell.execute_reply": "2024-09-24T10:51:58.301355Z"
    },
    "papermill": {
     "duration": 0.018537,
     "end_time": "2024-09-24T10:51:58.304069",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.285532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.global_avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc1 = nn.Conv2d(in_channels, in_channels // reduction, kernel_size=1)\n",
    "        self.fc2 = nn.Conv2d(in_channels // reduction, in_channels, kernel_size=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.global_avgpool(x)\n",
    "        y = self.fc1(y)\n",
    "        y = nn.ReLU()(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.sigmoid(y)\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a814d1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.324358Z",
     "iopub.status.busy": "2024-09-24T10:51:58.324100Z",
     "iopub.status.idle": "2024-09-24T10:51:58.330473Z",
     "shell.execute_reply": "2024-09-24T10:51:58.329679Z"
    },
    "papermill": {
     "duration": 0.018814,
     "end_time": "2024-09-24T10:51:58.332480",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.313666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LSTMBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(LSTMBlock, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c, h * w).permute(0, 2, 1)  # (batch_size, seq_len, input_size)\n",
    "        x, _ = self.lstm(x)\n",
    "        return x.permute(0, 2, 1).view(b, c, h, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "655b87a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.352907Z",
     "iopub.status.busy": "2024-09-24T10:51:58.352638Z",
     "iopub.status.idle": "2024-09-24T10:51:58.358653Z",
     "shell.execute_reply": "2024-09-24T10:51:58.357735Z"
    },
    "papermill": {
     "duration": 0.018337,
     "end_time": "2024-09-24T10:51:58.360540",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.342203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GRUBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1):\n",
    "        super(GRUBlock, self).__init__()\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        x = x.view(b, c, h * w).permute(0, 2, 1)\n",
    "        x, _ = self.gru(x)\n",
    "        return x.permute(0, 2, 1).view(b, c, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761d91dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.381098Z",
     "iopub.status.busy": "2024-09-24T10:51:58.380838Z",
     "iopub.status.idle": "2024-09-24T10:51:58.414281Z",
     "shell.execute_reply": "2024-09-24T10:51:58.413461Z"
    },
    "papermill": {
     "duration": 0.046007,
     "end_time": "2024-09-24T10:51:58.416120",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.370113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lớp chính HPYOLOv8 với các thay thế C2f, Concat bằng C2fDM và Fusion\n",
    "class HPYOLOv8(nn.Module):\n",
    "    \"\"\"\n",
    "    HPYOLOv8 class that extends the YOLOv8 model with custom modifications.\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path='yolov8x.pt'):\n",
    "        super().__init__()\n",
    "        self.model = YOLO(model_path)\n",
    "        \n",
    "        self.se_block = SEBlock(256)\n",
    "        self.lstm_block = LSTMBlock(256, 256)\n",
    "\n",
    "        # Thay thế các activation function trong mô hình YOLOv8 gốc\n",
    "        self.replace_activation(self.model.model)\n",
    "\n",
    "        # Thay thế C2f bằng C2fDM trong Backbone\n",
    "        self.replace_C2f_with_C2fDM()\n",
    "\n",
    "        # Thay thế Concat bằng Fusion và thêm BiFormer trong Neck\n",
    "        self.replace_Concat_with_Fusion_BiFormer()\n",
    "\n",
    "        # Thay thế FPN bằng BGFPN\n",
    "        self.replace_FPN_with_BGFPN()\n",
    "\n",
    "        # Thay thế CIoU Loss bằng SMPDIoU và thêm CBFocalLoss\n",
    "        self.replace_loss_functions()\n",
    "\n",
    "    def replace_activation(self, module):\n",
    "        \"\"\"\n",
    "        Recursively traverse the model and replace nn.SiLU with DyReLU.\n",
    "\n",
    "        Args:\n",
    "            module (nn.Module): The module to traverse.\n",
    "        \"\"\"\n",
    "        for name, child in module.named_children():\n",
    "            if isinstance(child, nn.SiLU):\n",
    "                # Giả sử số lượng kênh có thể được suy ra từ lớp trước đó\n",
    "                parent = module\n",
    "                # Kiểm tra xem lớp cha có attribute 'conv' hay không để lấy số kênh\n",
    "                if hasattr(parent, 'conv') and hasattr(parent.conv, 'out_channels'):\n",
    "                    out_channels = parent.conv.out_channels\n",
    "                    dyrelu = DyReLU(out_channels, reduction=4, k=2, conv_type='2d')\n",
    "                    setattr(module, name, dyrelu)\n",
    "                    print(f\"Replaced SiLU with DyReLU in layer: {name} with {out_channels} channels.\")\n",
    "                else:\n",
    "                    print(f\"Could not determine channels for layer: {name}. Skipping replacement.\")\n",
    "            else:\n",
    "                # Recursive call cho các module con\n",
    "                self.replace_activation(child)\n",
    "\n",
    "    def replace_C2f_with_C2fDM(self):\n",
    "        \"\"\"\n",
    "        Replace all instances of C2f with C2fDM in the Backbone.\n",
    "        \"\"\"\n",
    "        for i, layer in enumerate(self.model.model.model):\n",
    "            if isinstance(layer, nn.Sequential):\n",
    "                for j, sublayer in enumerate(layer):\n",
    "                    if type(sublayer).__name__ == \"C2f\":\n",
    "                        print(f\"Layer {i}.{j} is C2f, replacing with C2fDM.\")\n",
    "                        c1 = sublayer.cv1.conv.in_channels if hasattr(sublayer, 'cv1') and hasattr(sublayer.cv1, 'conv') else get_in_channels(sublayer.cv1)\n",
    "                        c2 = sublayer.cv2.conv.out_channels if hasattr(sublayer, 'cv2') and hasattr(sublayer.cv2, 'conv') else get_out_channels(sublayer.cv2)\n",
    "                        c2fdm = C2fDM(c1, c2)\n",
    "                        self.model.model.model[i][j] = c2fdm\n",
    "                        print(f\"Replaced C2f with C2fDM in layer {i}.{j}.\")\n",
    "            elif type(layer).__name__ == \"C2f\":\n",
    "                print(f\"Layer {i} is C2f, replacing with C2fDM.\")\n",
    "                c1 = layer.cv1.conv.in_channels if hasattr(layer, 'cv1') and hasattr(layer.cv1, 'conv') else get_in_channels(layer.cv1)\n",
    "                c2 = layer.cv2.conv.out_channels if hasattr(layer, 'cv2') and hasattr(layer.cv2, 'conv') else get_out_channels(layer.cv2)\n",
    "                c2fdm = C2fDM(c1, c2)\n",
    "                self.model.model.model[i] = c2fdm\n",
    "                print(f\"Replaced C2f with C2fDM in layer {i}.\")\n",
    "\n",
    "    def replace_Concat_with_Fusion_BiFormer(self):\n",
    "        \"\"\"\n",
    "        Replace all instances of Concat with Fusion and add BiFormer in the Neck.\n",
    "        \"\"\"\n",
    "        i = 0\n",
    "        while i < len(self.model.model.model):\n",
    "            layer = self.model.model.model[i]\n",
    "            if type(layer).__name__ == \"Concat\":\n",
    "                print(f\"Layer {i} is Concat, replacing with Fusion and adding BiFormer.\")\n",
    "                c1 = 0\n",
    "                for idx in layer.f:\n",
    "                    if idx < len(self.model.model.model):\n",
    "                        prev_layer = self.model.model.model[idx]\n",
    "                        out_channels = get_out_channels(prev_layer)\n",
    "                        c1 += out_channels\n",
    "                    else:\n",
    "                        print(f\"Invalid layer index {idx} in Concat layer {i}. Skipping.\")\n",
    "                if i + 1 < len(self.model.model.model):\n",
    "                    next_layer = self.model.model.model[i + 1]\n",
    "                    c2 = get_in_channels(next_layer)\n",
    "                else:\n",
    "                    c2 = c1\n",
    "                fusion_layer = Fusion(c1, c2)\n",
    "                biformer_layer = BiFormer(c1)\n",
    "                # Thay thế Concat bằng BiFormer và Fusion\n",
    "                self.model.model.model[i] = nn.Sequential(biformer_layer, fusion_layer)\n",
    "                print(f\"Replaced layer {i} with BiFormer and Fusion.\")\n",
    "                i += 1\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "    def replace_FPN_with_BGFPN(self):\n",
    "        \"\"\"\n",
    "        Replace the Feature Pyramid Network (FPN) with BGFPN.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            detect_layer = self.model.model.model[-1]\n",
    "            in_channels_list = [detect_layer.cv2[i][0].conv.in_channels for i in range(3)]\n",
    "            in_channels_list.insert(0, self.model.model.model[-4].conv.out_channels)\n",
    "            out_channels = detect_layer.cv2[0][-1].conv.out_channels if hasattr(detect_layer.cv2[0][-1], 'conv') else get_out_channels(detect_layer.cv2[0][-1])\n",
    "            bgfpn = BGFPN(in_channels_list, out_channels)\n",
    "            self.model.model.model[-1] = bgfpn\n",
    "            print(\"Replaced FPN with BGFPN.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to replace FPN with BGFPN: {e}\")\n",
    "\n",
    "    def replace_loss_functions(self):\n",
    "        \"\"\"\n",
    "        Replace CIoU Loss with SMPDIoU and add CBFocalLoss.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.model.model.model[-1].loss = SMPDIoU(alpha=0.75)  # Replace CIoU with SMPDIoU\n",
    "            self.focal_loss = CBFocalLoss(weights)  # Add CBFocalLoss\n",
    "            print(\"Replaced CIoU loss with SMPDIoU and added CBFocalLoss.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to replace loss functions: {e}\")\n",
    "\n",
    "    def add_callback(self, event, func):\n",
    "        \"\"\"\n",
    "        Forward the add_callback method to the internal YOLO model.\n",
    "\n",
    "        Args:\n",
    "            event (str): The event to attach the callback to.\n",
    "            func (callable): The callback function.\n",
    "        \"\"\"\n",
    "        if hasattr(self.model, 'add_callback'):\n",
    "            self.model.add_callback(event, func)\n",
    "            print(f\"Added callback for event '{event}'.\")\n",
    "        else:\n",
    "            raise AttributeError(f\"'YOLO' object has no attribute 'add_callback'\")\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         \"\"\"Forward pass through the YOLO model.\"\"\"\n",
    "#         return self.model(x)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model.backbone(x)  # Backbone with original layers\n",
    "        x = self.se_block(x)        # SE Block integration\n",
    "        x = self.lstm_block(x)      # LSTM Block integration\n",
    "        x = self.model.neck(x)      # Neck processing\n",
    "        return self.model.head(x)   # YOLO head output\n",
    "\n",
    "    def train_model(self, **kwargs):\n",
    "        \"\"\"Train the YOLO model with given parameters.\"\"\"\n",
    "        return self.model.train(**kwargs)\n",
    "\n",
    "    def val(self, **kwargs):\n",
    "        \"\"\"Validate the YOLO model with given parameters.\"\"\"\n",
    "        return self.model.val(**kwargs)\n",
    "\n",
    "    def predict(self, **kwargs):\n",
    "        \"\"\"Predict the YOLO model with given parameters.\"\"\"\n",
    "        return self.model.predict(**kwargs)\n",
    "    \n",
    "    @property\n",
    "    def trainer(self):\n",
    "        return getattr(self.model, 'trainer', None)\n",
    "    \n",
    "    def compute_loss(self, pred_boxes, gt_boxes, pred_classes, gt_classes):\n",
    "        \"\"\"\n",
    "        Compute the combined SMPDIoU and CBFocalLoss.\n",
    "\n",
    "        Args:\n",
    "            pred_boxes (Tensor): Predicted bounding boxes.\n",
    "            gt_boxes (Tensor): Ground truth bounding boxes.\n",
    "            pred_classes (Tensor): Predicted class logits.\n",
    "            gt_classes (Tensor): Ground truth class indices.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: Combined loss value.\n",
    "        \"\"\"\n",
    "        # Combine box loss (SMPDIoU) and classification loss (CBFocalLoss)\n",
    "        box_loss = self.model.model.model[-1].loss(pred_boxes, gt_boxes)\n",
    "\n",
    "        # Compute classification loss\n",
    "        class_loss = self.focal_loss(pred_classes, gt_classes)\n",
    "        total_loss = box_loss + class_loss\n",
    "\n",
    "        # Check if loss is negative\n",
    "        if total_loss.item() < 0:\n",
    "            print(\"Warning: Loss is negative\")\n",
    "\n",
    "        return total_loss\n",
    "\n",
    "    def replace_activation_in_model(self):\n",
    "        \"\"\"\n",
    "        Replace any remaining nn.SiLU activations in the YOLOv8 base model with DyReLU.\n",
    "        \"\"\"\n",
    "        def replace_act(module):\n",
    "            for name, child in module.named_children():\n",
    "                if isinstance(child, nn.SiLU):\n",
    "                    # Attempt to infer channels\n",
    "                    parent = module\n",
    "                    # Try to find the previous convolution layer's out_channels\n",
    "                    if hasattr(parent, 'conv') and hasattr(parent.conv, 'out_channels'):\n",
    "                        out_channels = parent.conv.out_channels\n",
    "                        dyrelu = DyReLU(out_channels, reduction=4, k=2, conv_type='2d')\n",
    "                        setattr(module, name, dyrelu)\n",
    "                        print(f\"Replaced SiLU with DyReLU in layer: {name} with {out_channels} channels.\")\n",
    "                    else:\n",
    "                        print(f\"Could not determine channels for layer: {name}. Skipping replacement.\")\n",
    "                else:\n",
    "                    replace_act(child)\n",
    "        replace_act(self.model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a73c12b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:51:58.436557Z",
     "iopub.status.busy": "2024-09-24T10:51:58.436259Z",
     "iopub.status.idle": "2024-09-24T10:52:00.811184Z",
     "shell.execute_reply": "2024-09-24T10:52:00.810263Z"
    },
    "papermill": {
     "duration": 2.38764,
     "end_time": "2024-09-24T10:52:00.813458",
     "exception": false,
     "start_time": "2024-09-24T10:51:58.425818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 160 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 640 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 80 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Replaced SiLU with DyReLU in layer: act with 320 channels.\n",
      "Layer 2 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 2.\n",
      "Layer 4 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 4.\n",
      "Layer 6 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 6.\n",
      "Layer 8 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 8.\n",
      "Layer 12 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 12.\n",
      "Layer 15 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 15.\n",
      "Layer 18 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 18.\n",
      "Layer 21 is C2f, replacing with C2fDM.\n",
      "Replaced C2f with C2fDM in layer 21.\n",
      "Layer 11 is Concat, replacing with Fusion and adding BiFormer.\n",
      "Replaced layer 11 with BiFormer and Fusion.\n",
      "Layer 14 is Concat, replacing with Fusion and adding BiFormer.\n",
      "Replaced layer 14 with BiFormer and Fusion.\n",
      "Layer 17 is Concat, replacing with Fusion and adding BiFormer.\n",
      "Replaced layer 17 with BiFormer and Fusion.\n",
      "Layer 20 is Concat, replacing with Fusion and adding BiFormer.\n",
      "Replaced layer 20 with BiFormer and Fusion.\n",
      "Replaced FPN with BGFPN.\n",
      "Replaced CIoU loss with SMPDIoU and added CBFocalLoss.\n",
      "Added callback for event 'on_pretrain_routine_start'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "# model = HPYOLOv8(model_path='yolov8x.pt')\n",
    "model = HPYOLOv8(model_path='/kaggle/input/vincxr-yolov8x-balancemax-hpyolov8-chestxray/vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour/weights/last.pt')\n",
    "\n",
    "# Add the dataset patch callback\n",
    "try:\n",
    "    model.add_callback(\"on_pretrain_routine_start\", patch_dataset)\n",
    "except AttributeError as e:\n",
    "    print(f\"Failed to add callback: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af0a05a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:52:00.836623Z",
     "iopub.status.busy": "2024-09-24T10:52:00.836200Z",
     "iopub.status.idle": "2024-09-24T10:52:00.840208Z",
     "shell.execute_reply": "2024-09-24T10:52:00.839372Z"
    },
    "papermill": {
     "duration": 0.017626,
     "end_time": "2024-09-24T10:52:00.842243",
     "exception": false,
     "start_time": "2024-09-24T10:52:00.824617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Print model summary\n",
    "# from torchsummary import summary\n",
    "# summary(model.model, input_size=(3, 640, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9babeacd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:52:00.863808Z",
     "iopub.status.busy": "2024-09-24T10:52:00.863519Z",
     "iopub.status.idle": "2024-09-24T10:52:00.875323Z",
     "shell.execute_reply": "2024-09-24T10:52:00.874472Z"
    },
    "papermill": {
     "duration": 0.026291,
     "end_time": "2024-09-24T10:52:00.878959",
     "exception": false,
     "start_time": "2024-09-24T10:52:00.852668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified YOLOv8 Architecture:\n",
      "YOLO(\n",
      "  (model): DetectionModel(\n",
      "    (model): Sequential(\n",
      "      (0): Conv(\n",
      "        (conv): Conv2d(3, 80, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (1): Conv(\n",
      "        (conv): Conv2d(80, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (2): C2fDM(\n",
      "        (cv1): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(240, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(80, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(40, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(40, 10, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=10, out_features=2, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=2, out_features=40, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(10, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=20, out_features=5, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(160, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (3): Conv(\n",
      "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (4): C2fDM(\n",
      "        (cv1): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(480, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=20, out_features=5, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(320, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (5): Conv(\n",
      "        (conv): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (6): C2fDM(\n",
      "        (cv1): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (7): Conv(\n",
      "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (8): C2fDM(\n",
      "        (cv1): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(640, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (9): SPPF(\n",
      "        (cv1): Conv(\n",
      "          (conv): Conv2d(640, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): DyReLU(\n",
      "            (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (cv2): Conv(\n",
      "          (conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "          (act): DyReLU(\n",
      "            (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (11): Sequential(\n",
      "        (0): BiFormer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=704, out_features=704, bias=True)\n",
      "          )\n",
      "          (ln): LayerNorm((704,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Fusion(\n",
      "          (conv): Conv2d(1984, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): DyReLU(\n",
      "            (fc1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Linear(in_features=320, out_features=5120, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (12): C2fDM(\n",
      "        (cv1): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
      "      (14): Sequential(\n",
      "        (0): BiFormer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)\n",
      "          )\n",
      "          (ln): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Fusion(\n",
      "          (conv): Conv2d(1344, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): DyReLU(\n",
      "            (fc1): Linear(in_features=960, out_features=240, bias=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Linear(in_features=240, out_features=3840, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (15): C2fDM(\n",
      "        (cv1): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(480, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(160, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(80, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=20, out_features=5, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=5, out_features=80, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(20, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (16): Conv(\n",
      "        (conv): Conv2d(320, 320, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (17): Sequential(\n",
      "        (0): BiFormer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=704, out_features=704, bias=True)\n",
      "          )\n",
      "          (ln): LayerNorm((704,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Fusion(\n",
      "          (conv): Conv2d(1664, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): DyReLU(\n",
      "            (fc1): Linear(in_features=960, out_features=240, bias=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Linear(in_features=240, out_features=3840, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (18): C2fDM(\n",
      "        (cv1): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (19): Conv(\n",
      "        (conv): Conv2d(640, 640, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (20): Sequential(\n",
      "        (0): BiFormer(\n",
      "          (attn): MultiheadAttention(\n",
      "            (out_proj): NonDynamicallyQuantizableLinear(in_features=704, out_features=704, bias=True)\n",
      "          )\n",
      "          (ln): LayerNorm((704,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "        (1): Fusion(\n",
      "          (conv): Conv2d(1984, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (act): DyReLU(\n",
      "            (fc1): Linear(in_features=1280, out_features=320, bias=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (fc2): Linear(in_features=320, out_features=5120, bias=True)\n",
      "            (sigmoid): Sigmoid()\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (21): C2fDM(\n",
      "        (cv1): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(960, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (m): Sequential(\n",
      "          (0): DMBottleneck(\n",
      "            (split): Sequential(\n",
      "              (0): Conv2d(320, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (osra): OSRA(\n",
      "              (conv): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (bn): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (idconv): IDConv(\n",
      "              (conv1): Conv2d(160, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=40, out_features=10, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=10, out_features=160, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(40, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=160, out_features=40, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=40, out_features=640, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "            (ste): STE(\n",
      "              (conv1): Conv2d(320, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act1): DyReLU(\n",
      "                (fc1): Linear(in_features=80, out_features=20, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=20, out_features=320, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "              (conv2): Conv2d(80, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (act2): DyReLU(\n",
      "                (fc1): Linear(in_features=320, out_features=80, bias=True)\n",
      "                (relu): ReLU(inplace=True)\n",
      "                (fc2): Linear(in_features=80, out_features=1280, bias=True)\n",
      "                (sigmoid): Sigmoid()\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (shortcut_conv): Conv2d(1280, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (shortcut_bn): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (shortcut_act): DyReLU(\n",
      "          (fc1): Linear(in_features=640, out_features=160, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=160, out_features=2560, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "      )\n",
      "      (22): BGFPN(\n",
      "        (cv1): Conv2d(2240, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act1): DyReLU(\n",
      "          (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (cv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (act2): DyReLU(\n",
      "          (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
      "          (relu): ReLU(inplace=True)\n",
      "          (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
      "          (sigmoid): Sigmoid()\n",
      "        )\n",
      "        (bra): BRA(\n",
      "          (q): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (k): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (v): Linear(in_features=64, out_features=64, bias=False)\n",
      "        )\n",
      "        (m): Sequential(\n",
      "          (0): C2fDM(\n",
      "            (cv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (act): DyReLU(\n",
      "              (fc1): Linear(in_features=64, out_features=16, bias=True)\n",
      "              (relu): ReLU(inplace=True)\n",
      "              (fc2): Linear(in_features=16, out_features=256, bias=True)\n",
      "              (sigmoid): Sigmoid()\n",
      "            )\n",
      "            (cv2): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (m): Sequential(\n",
      "              (0): DMBottleneck(\n",
      "                (split): Sequential(\n",
      "                  (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (2): DyReLU(\n",
      "                    (fc1): Linear(in_features=16, out_features=4, bias=True)\n",
      "                    (relu): ReLU(inplace=True)\n",
      "                    (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
      "                    (sigmoid): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "                (osra): OSRA(\n",
      "                  (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (act): DyReLU(\n",
      "                    (fc1): Linear(in_features=16, out_features=4, bias=True)\n",
      "                    (relu): ReLU(inplace=True)\n",
      "                    (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
      "                    (sigmoid): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "                (idconv): IDConv(\n",
      "                  (conv1): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (act1): DyReLU(\n",
      "                    (fc1): Linear(in_features=4, out_features=1, bias=True)\n",
      "                    (relu): ReLU(inplace=True)\n",
      "                    (fc2): Linear(in_features=1, out_features=16, bias=True)\n",
      "                    (sigmoid): Sigmoid()\n",
      "                  )\n",
      "                  (conv2): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (act2): DyReLU(\n",
      "                    (fc1): Linear(in_features=16, out_features=4, bias=True)\n",
      "                    (relu): ReLU(inplace=True)\n",
      "                    (fc2): Linear(in_features=4, out_features=64, bias=True)\n",
      "                    (sigmoid): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "                (ste): STE(\n",
      "                  (conv1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (bn1): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (act1): DyReLU(\n",
      "                    (fc1): Linear(in_features=8, out_features=2, bias=True)\n",
      "                    (relu): ReLU(inplace=True)\n",
      "                    (fc2): Linear(in_features=2, out_features=32, bias=True)\n",
      "                    (sigmoid): Sigmoid()\n",
      "                  )\n",
      "                  (conv2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                  (act2): DyReLU(\n",
      "                    (fc1): Linear(in_features=32, out_features=8, bias=True)\n",
      "                    (relu): ReLU(inplace=True)\n",
      "                    (fc2): Linear(in_features=8, out_features=128, bias=True)\n",
      "                    (sigmoid): Sigmoid()\n",
      "                  )\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (loss): SMPDIoU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Access the underlying YOLO model architecture\n",
    "yolo_model = model.model\n",
    "\n",
    "# Print the modified model architecture to verify changes\n",
    "print(\"Modified YOLOv8 Architecture:\")\n",
    "print(yolo_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efbd518f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:52:00.904258Z",
     "iopub.status.busy": "2024-09-24T10:52:00.903963Z",
     "iopub.status.idle": "2024-09-24T10:52:00.910216Z",
     "shell.execute_reply": "2024-09-24T10:52:00.909424Z"
    },
    "papermill": {
     "duration": 0.020003,
     "end_time": "2024-09-24T10:52:00.912016",
     "exception": false,
     "start_time": "2024-09-24T10:52:00.892013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define training parameters\n",
    "training_parameters = {\n",
    "    'data': '/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/data.yaml',\n",
    "    'epochs': 300,  # Increased epochs for better convergence\n",
    "    'batch': 32,    # Adjusted batch size based on GPU memory\n",
    "    'imgsz': 640,\n",
    "    'mixup': 0.5,   # Use MixUp with 50% probability\n",
    "    'augment': True,  # Enable data augmentation\n",
    "    'project': 'vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray',\n",
    "    'name': 'time11hour2',\n",
    "    'iou': 0.5,\n",
    "    'device': ','.join([str(i) for i in range(torch.cuda.device_count())]) if torch.cuda.is_available() else 'cpu',  # Use available devices\n",
    "    'exist_ok': True,\n",
    "    'verbose': True,\n",
    "    'time': 11,\n",
    "    'patience': 60  # Early stopping after 60 epochs without improvement\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c872915",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T10:52:00.936072Z",
     "iopub.status.busy": "2024-09-24T10:52:00.935787Z",
     "iopub.status.idle": "2024-09-24T21:58:27.621088Z",
     "shell.execute_reply": "2024-09-24T21:58:27.619876Z"
    },
    "papermill": {
     "duration": 39986.699907,
     "end_time": "2024-09-24T21:58:27.623283",
     "exception": false,
     "start_time": "2024-09-24T10:52:00.923376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Ultralytics YOLOv8.2.100 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/kaggle/input/vincxr-yolov8x-balancemax-hpyolov8-chestxray/vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour/weights/last.pt, data=/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/data.yaml, epochs=300, time=11, patience=60, batch=32, imgsz=640, save=True, save_period=-1, cache=False, device=0,1, workers=8, project=vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray, name=time11hour2, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.5, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=True, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.5, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 20.4MB/s]\n",
      "2024-09-24 10:52:02,882\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-09-24 10:52:03,427\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8733376  ultralytics.nn.modules.head.Detect           [16, [320, 640, 640]]         \n",
      "Model summary: 365 layers, 68,168,016 parameters, 68,168,000 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 54/595 items from pretrained weights\n",
      "\u001b[34m\u001b[1mDDP:\u001b[0m debug command /opt/conda/bin/python -m torch.distributed.run --nproc_per_node 2 --master_port 53831 /root/.config/Ultralytics/DDP/_temp_4xk_kask140645896688144.py\n",
      "Ultralytics YOLOv8.2.100 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: buithanhxuan2261 (buithanhxuan2261-xuan2261). Use `wandb login --relogin` to force relogin\n",
      "wandb: wandb version 0.18.1 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n",
      "wandb: Tracking run with wandb version 0.17.7\n",
      "wandb: Run data is saved locally in /kaggle/working/wandb/run-20240924_105227-p3hkos36\n",
      "wandb: Run `wandb offline` to turn off syncing.\n",
      "wandb: Syncing run time11hour2\n",
      "wandb: ⭐️ View project at https://wandb.ai/buithanhxuan2261-xuan2261/vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray\n",
      "wandb: 🚀 View run at https://wandb.ai/buithanhxuan2261-xuan2261/vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/runs/p3hkos36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 595/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.25M/6.25M [00:00<00:00, 112MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train/labels... 11250 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11250/11250 [00:50<00:00, 222.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train is not writeable, cache not saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n",
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train/labels... 77 images, 0 backgrounds, 0 corrupt:   1%|          | 77/11250 [00:00<00:15, 698.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train/labels... 11250 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11250/11250 [00:12<00:00, 879.69it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/val/labels... 3000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3000/3000 [00:14<00:00, 213.16it/s]\n",
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.14). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/val is not writeable, cache not saved.\n",
      "Plotting labels to vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 640 train, 640 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mvincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2\u001b[0m\n",
      "Starting training for 11 hours...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/300      13.5G        inf      0.577      1.047         64        640: 100%|██████████| 352/352 [08:02<00:00,  1.37s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.465      0.471      0.446      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/68      13.2G     0.3944     0.5884       1.05         45        640: 100%|██████████| 352/352 [07:56<00:00,  1.35s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.448      0.452      0.422      0.268\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/69      13.2G     0.4101     0.6322      1.053         62        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.404      0.425      0.375      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/69      13.1G     0.4278     0.6954      1.069         67        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.429      0.399      0.366      0.241\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/69      13.2G     0.4368     0.7152      1.076        108        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612       0.45      0.379      0.376      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/70      13.1G     0.4274     0.7075       1.07         74        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.453      0.426      0.404      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/70      13.1G     0.4307     0.7075      1.071         67        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.463      0.428      0.411      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/70      13.1G     0.4289      0.705      1.064        102        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.405      0.369      0.348      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/70      13.2G     0.4239     0.6983      1.067         64        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.448      0.422      0.401      0.255\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/70      13.2G     0.4192     0.6869      1.066         81        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.403      0.389      0.364      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/70      13.2G     0.4219     0.6881      1.065         55        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.413      0.424      0.406      0.253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/70      13.2G     0.4323     0.7101      1.071         70        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.461       0.41      0.393      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/70      13.1G     0.4128     0.6744       1.06         71        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.441      0.441      0.404      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/70      13.2G      0.422      0.682      1.063         82        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.494      0.422      0.419      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/70      13.2G        inf     0.6851      1.068         56        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.466      0.419      0.404      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/70      13.1G     0.4147     0.6654      1.062         67        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.449      0.421      0.408      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/70      13.2G     0.4226     0.6742      1.065         59        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.463      0.428      0.406      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/70      13.2G     0.4078     0.6594      1.057         99        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.443      0.432      0.409      0.259\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/70      13.2G     0.4034     0.6534      1.058         71        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.462      0.437       0.42      0.269\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/70      13.2G     0.4112     0.6584      1.058         55        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.432      0.447      0.403      0.258\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/70      13.1G      0.408     0.6528      1.057         61        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.481      0.449      0.439      0.273\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/70        13G     0.4122     0.6497      1.057         48        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.449      0.442      0.422      0.267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/70      13.2G     0.4161     0.6494      1.061         95        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.462      0.427      0.412      0.261\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/70      13.1G        inf     0.6421      1.058         77        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.488      0.439       0.43      0.271\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/70      13.1G      0.417     0.6542      1.062         51        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.499      0.442      0.434       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      26/70      13.2G     0.4041     0.6387      1.054        102        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.493      0.451       0.44      0.278\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      27/70      13.1G     0.4085     0.6277      1.057         93        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.494      0.448      0.441      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      28/70      13.1G     0.4018     0.6259      1.059         59        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.489      0.445       0.44      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      29/70      13.1G     0.3997     0.6245       1.05         56        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.473      0.456      0.434      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      30/70      13.2G     0.4002     0.6204      1.054         76        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.487      0.458      0.441      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      31/70      13.1G      0.407       0.62      1.057         93        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.495       0.46      0.448      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      32/70      13.1G     0.4064     0.6225      1.056         81        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.483      0.454      0.443      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      33/70      13.1G     0.3989     0.6126      1.052         73        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.492      0.455      0.442       0.28\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      34/70      13.2G     0.3923     0.6021      1.048         82        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.483      0.467      0.449      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      35/70      13.1G     0.3913     0.5987      1.053         35        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612        0.5      0.465      0.458      0.285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      36/70        13G     0.3913      0.595      1.048         62        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.497      0.461      0.445      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      37/70      13.1G     0.3924     0.5867      1.048         68        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.476       0.48      0.447      0.279\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      38/70      13.1G     0.3897     0.5984       1.05         95        640: 100%|██████████| 352/352 [07:52<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.507      0.465      0.459       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      39/70      13.2G     0.3998     0.5988      1.053         77        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.503      0.464      0.453      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      40/70      13.2G     0.3965      0.591       1.05         60        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.487      0.461      0.447      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      41/70      13.2G     0.3911     0.5897      1.049         81        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.507      0.464      0.459      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      42/70      13.1G     0.3792     0.5763       1.04         50        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.505      0.453      0.455      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      43/70      13.2G     0.3951     0.5857      1.048         99        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.506      0.464      0.456      0.286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      44/70      13.1G        inf     0.5728      1.042         72        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.523      0.456      0.455      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      45/70      13.1G     0.3942     0.5863      1.052         61        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.503      0.468      0.458      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      46/70      13.1G     0.3824     0.5649      1.044         52        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.524       0.46      0.464      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      47/70      13.2G     0.3877     0.5595      1.046         91        640: 100%|██████████| 352/352 [07:51<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.502      0.466      0.456       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      48/70      13.1G        inf     0.5572      1.041         73        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.492      0.473      0.462      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      49/70      13.1G     0.3764      0.553      1.037         75        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.493      0.464      0.456      0.288\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      50/70      13.1G     0.3784     0.5532      1.042         97        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:34<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.499      0.468      0.455      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      51/70      13.1G     0.3667      0.529      1.035         69        640: 100%|██████████| 352/352 [07:50<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.507      0.471       0.46      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      52/70      13.2G      0.375     0.5446      1.042        110        640: 100%|██████████| 352/352 [07:49<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.495      0.469      0.455      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      53/70      13.2G     0.3688     0.5237      1.033         71        640: 100%|██████████| 352/352 [07:49<00:00,  1.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.497      0.472      0.462      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      54/70      13.1G      0.364     0.5259      1.031        118        640: 100%|██████████| 352/352 [07:48<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.511      0.465      0.463      0.295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      55/70      13.1G     0.3748     0.5366      1.038         73        640: 100%|██████████| 352/352 [07:47<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612       0.51      0.463      0.461      0.292\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      56/70      13.1G     0.3758     0.5386      1.037         44        640: 100%|██████████| 352/352 [07:46<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.501      0.475       0.46      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      57/70      13.2G     0.3824     0.5359      1.041         49        640: 100%|██████████| 352/352 [07:46<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.518      0.461      0.459      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      58/70      13.2G     0.3686     0.5168      1.031         52        640: 100%|██████████| 352/352 [07:47<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.533       0.45      0.464      0.293\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      59/70      13.2G     0.3684     0.5173      1.031         62        640: 100%|██████████| 352/352 [07:47<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.532      0.454      0.461      0.294\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      60/70      13.2G     0.3676     0.5103      1.028         41        640: 100%|██████████| 352/352 [07:48<00:00,  1.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.532       0.45      0.459      0.293\n",
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      61/70      13.2G     0.5104     0.5009      1.119         22        640: 100%|██████████| 352/352 [07:46<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.524      0.458      0.459      0.291\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      62/70      13.2G     0.4967     0.4754      1.109         26        640: 100%|██████████| 352/352 [07:45<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612       0.51      0.466      0.454       0.29\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      63/70      13.2G     0.4892     0.4601      1.106         18        640: 100%|██████████| 352/352 [07:45<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.494      0.466      0.453      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      64/70      13.2G     0.4836     0.4519      1.096         20        640: 100%|██████████| 352/352 [07:45<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612        0.5      0.463      0.453      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      65/70      13.2G        inf      0.424      1.087         42        640: 100%|██████████| 352/352 [07:43<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.496       0.47      0.451      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      66/70      13.1G     0.4814     0.4378      1.091         36        640: 100%|██████████| 352/352 [07:42<00:00,  1.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.503      0.462      0.452      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      67/70      13.2G     0.4703      0.425       1.09         35        640: 100%|██████████| 352/352 [07:42<00:00,  1.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.497       0.47      0.452      0.289\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      68/70      13.2G      0.461     0.4161      1.087         37        640: 100%|██████████| 352/352 [07:39<00:00,  1.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.499      0.467       0.45      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      69/70      13.2G     0.4674     0.4154      1.083          9        640: 100%|██████████| 352/352 [07:39<00:00,  1.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.504      0.463      0.449      0.287\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      70/70      13.2G     0.4593     0.4095      1.081         11        640: 100%|██████████| 352/352 [07:38<00:00,  1.30s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [01:33<00:00,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.502      0.465      0.447      0.285\n",
      "\n",
      "70 epochs completed in 11.006 hours.\n",
      "Optimizer stripped from vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2/weights/last.pt, 136.8MB\n",
      "Optimizer stripped from vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2/weights/best.pt, 136.8MB\n",
      "\n",
      "Validating vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.100 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 268 layers, 68,138,976 parameters, 0 gradients, 257.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [03:22<00:00,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.507      0.494      0.474      0.302\n",
      "    Aortic_enlargement        593        655      0.741      0.876      0.886       0.56\n",
      "           Atelectasis         38         46      0.379      0.261      0.193     0.0785\n",
      "         Calcification         84        137      0.313      0.321      0.206      0.078\n",
      "          Cardiomegaly        447        475      0.769      0.893      0.899      0.638\n",
      "         Consolidation         61         69      0.342      0.385      0.366      0.186\n",
      "                   ILD         87        176      0.379      0.386      0.363      0.156\n",
      "          Infiltration        119        176      0.409      0.417      0.359      0.158\n",
      "          Lung_Opacity        253        365       0.34      0.329      0.256      0.102\n",
      "           Nodule/Mass        146        394      0.458      0.335      0.335      0.143\n",
      "          Other_lesion        234        385      0.335      0.221      0.189     0.0653\n",
      "      Pleural_effusion        201        345      0.583        0.4      0.482      0.195\n",
      "    Pleural_thickening        369        753      0.397      0.297      0.281     0.0872\n",
      "          Pneumothorax         20         28      0.383      0.464      0.461      0.294\n",
      "    Pulmonary_fibrosis        295        608      0.412      0.359      0.329      0.118\n",
      "            No finding       2138       2138      0.965      0.991      0.991      0.991\n",
      "               Finding        862        862      0.913      0.972      0.984      0.984\n",
      "Speed: 0.2ms preprocess, 63.7ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mvincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:                                                                                \n",
      "wandb: \n",
      "wandb: Run history:\n",
      "wandb:                  lr/pg0 ▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "wandb:                  lr/pg1 ▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "wandb:                  lr/pg2 ▃▆███▇▇▇▇▇▇▆▆▆▆▆▅▅▅▅▅▄▄▄▄▄▃▃▃▃▃▃▂▂▂▂▂▁▁▁\n",
      "wandb:        metrics/mAP50(B) ▆▅▂▄▁▄▄▄▄▄▄▄▅▆▆▆▆▇▆▇▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█\n",
      "wandb:     metrics/mAP50-95(B) ▆▅▂▃▁▃▃▃▄▃▄▃▄▅▅▅▅▆▆▆▆▇▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇▇█\n",
      "wandb:    metrics/precision(B) ▄▃▂▄▁▃▁▃▄▃▃▂▃▆▆▆▅▆▅▅▆▇▆▇▇▆▆▆▆▆▇▇▇██▇▆▆▆▇\n",
      "wandb:       metrics/recall(B) ▇▆▃▄▁▄▄▅▄��▄▅▅▅▅▅▆▆▆▆▆▆▆▆▆▇▆▇▇▇▆▆▆▆▆▆▆▆▆█\n",
      "wandb:            model/GFLOPs ▁\n",
      "wandb:        model/parameters ▁\n",
      "wandb: model/speed_PyTorch(ms) ▁\n",
      "wandb:          train/box_loss  ▂▄▄▄▄▄▃ ▃▃▃▃ ▄▃▃▃▃▂▂▂▃▂▂▂▂ ▂▂▁▂▂▁█▇▇▇▆▆\n",
      "wandb:          train/cls_loss ▅▅█████▇▇▇▇▇▇▆▇▆▆▆▆▆▅▅▅▅▅▅▅▄▄▄▄▄▄▄▃▃▂▂▁▁\n",
      "wandb:          train/dfl_loss ▂▃▄▄▄▄▄▃▄▄▃▃▃▃▃▃▃▃▃▂▂▃▃▂▂▃▂▂▂▂▁▂▂▁█▇▆▆▅▅\n",
      "wandb:            val/box_loss ▁▃▅▅█▄▅▄▆▃▃▃▅▄▇▅▂▂▂▄▃▃▂▂▄▃▄▄▄▄▅▅▄▄▅▅▅▆▅▅\n",
      "wandb:            val/cls_loss ▁▃▇▄█▅▅▄▄▃▃▃▄▃▅▄▂▁▂▃▂▂▁▁▂▂▂▃▂▂▂▃▃▂▂▂▃▃▃▃\n",
      "wandb:            val/dfl_loss ▁▃▅▆█▅��▄▆▃▃▃▄▄▇▅▂▂▂▄▃▃▂▂▄▃▃▃▄▄▄▅▄▃▄▅▅▆▅▅\n",
      "wandb: \n",
      "wandb: Run summary:\n",
      "wandb:                  lr/pg0 0.00024\n",
      "wandb:                  lr/pg1 0.00024\n",
      "wandb:                  lr/pg2 0.00024\n",
      "wandb:        metrics/mAP50(B) 0.47376\n",
      "wandb:     metrics/mAP50-95(B) 0.30219\n",
      "wandb:    metrics/precision(B) 0.50746\n",
      "wandb:       metrics/recall(B) 0.4942\n",
      "wandb:            model/GFLOPs 258.203\n",
      "wandb:        model/parameters 68168016\n",
      "wandb: model/speed_PyTorch(ms) 27.608\n",
      "wandb:          train/box_loss 0.45934\n",
      "wandb:          train/cls_loss 0.40952\n",
      "wandb:          train/dfl_loss 1.08126\n",
      "wandb:            val/box_loss 0.72398\n",
      "wandb:            val/cls_loss 0.81567\n",
      "wandb:            val/dfl_loss 0.79913\n",
      "wandb: \n",
      "wandb: 🚀 View run time11hour2 at: https://wandb.ai/buithanhxuan2261-xuan2261/vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/runs/p3hkos36\n",
      "wandb: ⭐️ View project at: https://wandb.ai/buithanhxuan2261-xuan2261/vincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray\n",
      "wandb: Synced 5 W&B file(s), 21 media file(s), 5 artifact file(s) and 0 other file(s)\n",
      "wandb: Find logs at: ./wandb/run-20240924_105227-p3hkos36/logs\n",
      "wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Train the model with the defined parameters\n",
    "print(\"Starting training...\")\n",
    "results = model.train_model(**training_parameters)\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cfe2add2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T21:58:33.133289Z",
     "iopub.status.busy": "2024-09-24T21:58:33.132355Z",
     "iopub.status.idle": "2024-09-24T22:06:37.145495Z",
     "shell.execute_reply": "2024-09-24T22:06:37.144419Z"
    },
    "papermill": {
     "duration": 486.74695,
     "end_time": "2024-09-24T22:06:37.147606",
     "exception": false,
     "start_time": "2024-09-24T21:58:30.400656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting validation...\n",
      "Ultralytics YOLOv8.2.100 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n",
      "Model summary (fused): 268 layers, 68,138,976 parameters, 0 gradients, 257.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/val/labels... 3000 images, 0 backgrounds, 0 corrupt: 100%|██████████| 3000/3000 [00:03<00:00, 799.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/val is not writeable, cache not saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 94/94 [07:52<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3000       7612      0.507      0.493      0.473      0.302\n",
      "    Aortic_enlargement        593        655      0.742      0.876      0.886      0.558\n",
      "           Atelectasis         38         46      0.379      0.261      0.195     0.0789\n",
      "         Calcification         84        137      0.312      0.321      0.205     0.0788\n",
      "          Cardiomegaly        447        475      0.771      0.893      0.899      0.639\n",
      "         Consolidation         61         69      0.351      0.391      0.368      0.187\n",
      "                   ILD         87        176      0.378      0.386      0.357      0.156\n",
      "          Infiltration        119        176      0.409      0.415      0.359      0.158\n",
      "          Lung_Opacity        253        365      0.343      0.329      0.256      0.102\n",
      "           Nodule/Mass        146        394       0.45      0.328      0.331      0.145\n",
      "          Other_lesion        234        385      0.337      0.218       0.19     0.0647\n",
      "      Pleural_effusion        201        345      0.574       0.39      0.478      0.195\n",
      "    Pleural_thickening        369        753        0.4      0.297      0.281     0.0878\n",
      "          Pneumothorax         20         28      0.384      0.464      0.461      0.294\n",
      "    Pulmonary_fibrosis        295        608       0.41      0.357      0.327      0.118\n",
      "            No finding       2138       2138      0.965      0.991      0.991      0.991\n",
      "               Finding        862        862      0.913      0.972      0.984      0.984\n",
      "Speed: 0.2ms preprocess, 153.2ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mvincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2\u001b[0m\n",
      "Validation completed.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the validation set\n",
    "print(\"Starting validation...\")\n",
    "val_results = model.val(iou=0.5)\n",
    "print(\"Validation completed.\")\n",
    "# print(\"Validation Results:\")\n",
    "# print(val_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da3a1dae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T22:06:42.658527Z",
     "iopub.status.busy": "2024-09-24T22:06:42.657749Z",
     "iopub.status.idle": "2024-09-24T22:08:52.538724Z",
     "shell.execute_reply": "2024-09-24T22:08:52.537446Z"
    },
    "papermill": {
     "duration": 132.611301,
     "end_time": "2024-09-24T22:08:52.541023",
     "exception": false,
     "start_time": "2024-09-24T22:06:39.929722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test evaluation...\n",
      "Ultralytics YOLOv8.2.100 🚀 Python-3.10.14 torch-2.4.0 CUDA:0 (Tesla T4, 15095MiB)\n",
      "                                                       CUDA:1 (Tesla T4, 15095MiB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/test/labels... 750 images, 0 backgrounds, 0 corrupt: 100%|██████████| 750/750 [00:03<00:00, 193.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/test is not writeable, cache not saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 24/24 [02:00<00:00,  5.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        750       1999      0.488      0.467      0.471      0.296\n",
      "    Aortic_enlargement        147        162      0.769      0.901      0.926      0.606\n",
      "           Atelectasis         18         20      0.337        0.3      0.272     0.0821\n",
      "         Calcification         23         28      0.362       0.25      0.292     0.0971\n",
      "          Cardiomegaly         96         99      0.671      0.919       0.93      0.641\n",
      "         Consolidation         14         17      0.387      0.529      0.416      0.188\n",
      "                   ILD         18         36      0.306      0.361      0.347      0.166\n",
      "          Infiltration         34         53      0.403      0.472      0.401      0.176\n",
      "          Lung_Opacity         73        116      0.403      0.262      0.311      0.124\n",
      "           Nodule/Mass         35         74      0.468      0.338      0.345        0.2\n",
      "          Other_lesion         50         91      0.278      0.121      0.113     0.0451\n",
      "      Pleural_effusion         52         97      0.584      0.361      0.479      0.184\n",
      "    Pleural_thickening        113        238      0.417      0.277      0.295     0.0985\n",
      "          Pneumothorax          3          3          0          0     0.0185    0.00688\n",
      "    Pulmonary_fibrosis        100        215      0.536      0.392      0.405       0.14\n",
      "            No finding        530        530      0.967      0.996      0.995      0.995\n",
      "               Finding        220        220      0.926      0.995      0.993      0.993\n",
      "Speed: 0.2ms preprocess, 154.0ms inference, 0.0ms loss, 0.8ms postprocess per image\n",
      "Results saved to \u001b[1mvincxr_yolov8x_balanceMax_HPYOLOv8_ChestXray/time11hour2\u001b[0m\n",
      "Test Evaluation completed.\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "print(\"Starting test evaluation...\")\n",
    "test_results = model.val(iou=0.5, split='test')\n",
    "print(\"Test Evaluation completed.\")\n",
    "# print(\"Test Results:\")\n",
    "# print(test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40b8aa9",
   "metadata": {
    "papermill": {
     "duration": 2.722441,
     "end_time": "2024-09-24T22:08:58.008478",
     "exception": false,
     "start_time": "2024-09-24T22:08:55.286037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37999fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T22:09:03.437375Z",
     "iopub.status.busy": "2024-09-24T22:09:03.436365Z",
     "iopub.status.idle": "2024-09-24T22:09:05.504644Z",
     "shell.execute_reply": "2024-09-24T22:09:05.503695Z"
    },
    "papermill": {
     "duration": 4.77673,
     "end_time": "2024-09-24T22:09:05.506759",
     "exception": false,
     "start_time": "2024-09-24T22:09:00.730029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phân phối lớp trong dữ liệu huấn luyện: Counter({14: 677, 15: 323, 11: 277, 0: 251, 13: 202, 3: 185, 8: 162, 7: 155, 9: 138, 10: 113, 2: 50, 5: 49, 6: 45, 4: 28, 12: 10, 1: 8})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def verify_class_balance(file_path, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Kiểm tra cân bằng lớp trong dataset.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Đường dẫn tới tệp dữ liệu huấn luyện (train.txt).\n",
    "        num_samples (int): Số lượng mẫu để kiểm tra.\n",
    "\n",
    "    Returns:\n",
    "        Counter: Số lượng của từng lớp.\n",
    "    \"\"\"\n",
    "    labels = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        image_paths = f.read().splitlines()\n",
    "\n",
    "    # Giả định rằng nhãn được lưu trong các tệp .txt tương ứng\n",
    "    for img_path in image_paths[:num_samples]:\n",
    "        label_path = img_path.replace('/images/', '/labels/').replace('.jpg', '.txt')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as lf:\n",
    "                for line in lf:\n",
    "                    class_id = int(line.split()[0])\n",
    "                    labels.append(class_id)\n",
    "\n",
    "    return Counter(labels)\n",
    "\n",
    "# Sử dụng\n",
    "train_file = '/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train.txt'\n",
    "class_counts = verify_class_balance(train_file, num_samples=1000)\n",
    "print(\"Phân phối lớp trong dữ liệu huấn luyện:\", class_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f29621cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T22:09:11.052265Z",
     "iopub.status.busy": "2024-09-24T22:09:11.051339Z",
     "iopub.status.idle": "2024-09-24T22:09:11.062903Z",
     "shell.execute_reply": "2024-09-24T22:09:11.061991Z"
    },
    "papermill": {
     "duration": 2.733102,
     "end_time": "2024-09-24T22:09:11.064969",
     "exception": false,
     "start_time": "2024-09-24T22:09:08.331867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def verify_class_balance(dataset, num_samples=1000):\n",
    "    \"\"\"\n",
    "    Verifies whether the __getitem__ method in the YOLOWeightedDataset class returns a balanced class output.\n",
    "\n",
    "    Args:\n",
    "        dataset: An instance of YOLOWeightedDataset.\n",
    "        num_samples: Number of samples to draw from the dataset.\n",
    "\n",
    "    Returns:\n",
    "        class_counts: A dictionary containing the class counts.\n",
    "    \"\"\"\n",
    "    all_labels = []\n",
    "\n",
    "    if dataset.train_mode:\n",
    "        choices = np.random.choice(len(dataset.labels), size=num_samples, p=dataset.probabilities)\n",
    "    else:\n",
    "        choices = range(len(dataset.labels))\n",
    "\n",
    "    for i in choices:\n",
    "        label = dataset.labels[i][\"cls\"]\n",
    "        all_labels.extend(label.reshape(-1).astype(int))\n",
    "\n",
    "    class_counts = Counter(all_labels)\n",
    "    return class_counts\n",
    "\n",
    "def plot_class_balance(weighted_cnts, unweighted_cnts, class_names):\n",
    "    \"\"\"\n",
    "    Plots the comparison of class distribution between training and validation modes.\n",
    "\n",
    "    Args:\n",
    "        weighted_cnts: A dictionary containing the class counts in weighted mode.\n",
    "        unweighted_cnts: A dictionary containing the class counts in unweighted mode.\n",
    "        class_names: A list of class names.\n",
    "    \"\"\"\n",
    "    classes = range(len(class_names))\n",
    "    weighted_values = [weighted_cnts.get(c, 0) for c in classes]\n",
    "    unweighted_values = [unweighted_cnts.get(c, 0) for c in classes]\n",
    "\n",
    "    width = 0.35  # Bar width\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(classes, unweighted_values, width, label='Normal mode')\n",
    "    ax.bar([c + width for c in classes], weighted_values, width, label='Weighted Mode')\n",
    "\n",
    "    ax.set_xlabel('Class')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Class Distribution in Normal vs Weighted Modes')\n",
    "    ax.set_xticks([c + width / 2 for c in classes])\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73432384",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T22:09:16.454879Z",
     "iopub.status.busy": "2024-09-24T22:09:16.454478Z",
     "iopub.status.idle": "2024-09-24T22:09:31.654982Z",
     "shell.execute_reply": "2024-09-24T22:09:31.653986Z"
    },
    "papermill": {
     "duration": 17.896089,
     "end_time": "2024-09-24T22:09:31.657072",
     "exception": false,
     "start_time": "2024-09-24T22:09:13.760983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLODataset has been monkey-patched with YOLOWeightedDataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train/labels... 11250 images, 0 backgrounds, 0 corrupt: 100%|██████████| 11250/11250 [00:14<00:00, 801.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train is not writeable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### https://y-t-g.github.io/tutorials/yolo-class-balancing/\n",
    "\n",
    "# Specify a batch size\n",
    "batch_size = 16  # or any appropriate value\n",
    "\n",
    "# # Apply the monkey-patch\n",
    "# patch_dataset(model.trainer)\n",
    "\n",
    "if model.trainer is not None:\n",
    "    patch_dataset(model.trainer)\n",
    "    # Tiếp tục xây dựng dataset\n",
    "else:\n",
    "    print(\"Trainer chưa được khởi tạo.\")\n",
    "\n",
    "# Now build the dataset with the patched class\n",
    "trainset = model.trainer.build_dataset('/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/train.txt', mode='train', batch=batch_size)\n",
    "\n",
    "# Now you can proceed to modify the dataset attributes as needed\n",
    "trainset.agg_func = np.sum\n",
    "trainset.weights = trainset.calculate_weights()\n",
    "trainset.probabilities = trainset.calculate_probabilities()\n",
    "\n",
    "# Verify class balance in training mode\n",
    "trainset.train_mode = True\n",
    "train_counts = verify_class_balance(trainset, num_samples=1000)\n",
    "\n",
    "# Verify class balance in validation mode\n",
    "trainset.train_mode = False\n",
    "val_counts = verify_class_balance(trainset, num_samples=1000)\n",
    "\n",
    "# Plot the comparison\n",
    "plot_class_balance(train_counts, val_counts, list(trainset.data[\"names\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f26a6b8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-24T22:09:37.169680Z",
     "iopub.status.busy": "2024-09-24T22:09:37.168761Z",
     "iopub.status.idle": "2024-09-24T22:09:37.581739Z",
     "shell.execute_reply": "2024-09-24T22:09:37.580287Z"
    },
    "papermill": {
     "duration": 3.205888,
     "end_time": "2024-09-24T22:09:37.584139",
     "exception": true,
     "start_time": "2024-09-24T22:09:34.378251",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ngưỡng của từng lớp: [0.8037647776698476, 0.3088698066808813, 0.316387969428949, 0.8274848603727791, 0.3698186995540763, 0.3818808500645518, 0.41182734488302886, 0.33582849931361275, 0.37900169691830354, 0.26497349279413035, 0.46427795950718176, 0.3413579323027201, 0.42006590542621197, 0.38181554689325375, 0.9777918226727478, 0.9418244956556391]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "HPYOLOv8.predict() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Dự đoán trên ảnh mới\u001b[39;00m\n\u001b[1;32m     44\u001b[0m img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/test/images/0005e8e3701dfb1dd93d53e2ff537b6e.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 45\u001b[0m boxes, scores, class_ids \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_with_thresholds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSố lượng dự đoán:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(boxes))\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mThông tin chi tiết các hộp dự đoán:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[27], line 24\u001b[0m, in \u001b[0;36mpredict_with_thresholds\u001b[0;34m(img_path)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_with_thresholds\u001b[39m(img_path):\n\u001b[0;32m---> 24\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miou\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.45\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43magnostic_nms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_det\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m300\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     boxes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     27\u001b[0m     scores \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: HPYOLOv8.predict() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Đưa ra ngưỡng riêng cho từng lớp\n",
    "class_thresholds = [0.5] * len(val_results.box.ap50)  # Khởi tạo ngưỡng mặc định cho tất cả các lớp\n",
    "\n",
    "for class_id in range(len(val_results.box.ap50)):\n",
    "    if class_id < len(val_results.box.p):  # Kiểm tra xem class_id có hợp lệ không\n",
    "        precision = val_results.box.p[class_id]\n",
    "        recall = val_results.box.r[class_id]\n",
    "        f1 = val_results.box.f1[class_id]\n",
    "        \n",
    "        #  Sử dụng F1 score làm ngưỡng cho mỗi lớp thay vì trung bình của precision và recall. F1 score là một thước đo cân bằng giữa precision và recall.\n",
    "        #  Đặt ngưỡng tối thiểu là 0.1 để tránh ngưỡng quá thấp có thể dẫn đến quá nhiều dự đoán sai.\n",
    "        \n",
    "        # Tính ngưỡng tối ưu dựa trên F1 score\n",
    "        threshold = f1  # Sử dụng F1 score làm ngưỡng\n",
    "        \n",
    "        class_thresholds[class_id] = max(threshold, 0.01)  # Đặt ngưỡng tối thiểu là 0.1\n",
    "\n",
    "print(\"Ngưỡng của từng lớp:\", class_thresholds)\n",
    "\n",
    "# Hàm dự đoán với ngưỡng riêng cho từng lớp\n",
    "def predict_with_thresholds(img_path):\n",
    "    results = model.predict(img_path, conf=0.01, iou=0.45, agnostic_nms=True, device='0', max_det=300)\n",
    "    \n",
    "    boxes = []\n",
    "    scores = []\n",
    "    class_ids = []\n",
    "    \n",
    "    for result in results:\n",
    "        for box, score, class_id in zip(result.boxes.xyxy, result.boxes.conf, result.boxes.cls):\n",
    "            class_id = int(class_id)\n",
    "            if class_id < len(class_thresholds) and score >= class_thresholds[class_id]:\n",
    "                boxes.append(box.tolist())\n",
    "                scores.append(float(score))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    return boxes, scores, class_ids\n",
    "\n",
    "# Danh sách tên lớp\n",
    "class_names = ['Aortic_enlargement', 'Atelectasis', 'Calcification', 'Cardiomegaly', 'Consolidation', 'ILD', 'Infiltration', 'Lung_Opacity', 'Nodule/Mass', 'Other_lesion', 'Pleural_effusion', 'Pleural_thickening', 'Pneumothorax', 'Pulmonary_fibrosis', 'No finding', 'Finding']\n",
    "\n",
    "# Dự đoán trên ảnh mới\n",
    "img_path = '/kaggle/input/vinbigdata-yolo-dataset-with-wbf-640px-16class/vinbigdata-yolo-dataset-with-wbf-640px-16class/test/images/0005e8e3701dfb1dd93d53e2ff537b6e.jpg'\n",
    "boxes, scores, class_ids = predict_with_thresholds(img_path)\n",
    "\n",
    "print(\"Số lượng dự đoán:\", len(boxes))\n",
    "print(\"\\nThông tin chi tiết các hộp dự đoán:\")\n",
    "for i, (box, score, class_id) in enumerate(zip(boxes, scores, class_ids)):\n",
    "    print(f\"Dự đoán {i+1}:\")\n",
    "    print(f\"  Hộp giới hạn: {box}\")\n",
    "    print(f\"  Độ tự tin: {score:.4f}\")\n",
    "    print(f\"  Lớp ID: {class_id}\")\n",
    "    print(f\"  Tên lớp: {class_names[class_id]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a3db84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5719062,
     "sourceId": 9416880,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 197864343,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 40759.169123,
   "end_time": "2024-09-24T22:09:43.257924",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-24T10:50:24.088801",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
